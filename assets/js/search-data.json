{
  
    
        "post0": {
            "title": "Hypothesis Testing",
            "content": "Framework . We start with a null hypothesis (H0) that represents the currect state ( Nothing going on, =, &lt;=, &gt;=) | We also have an alternative hypothesis(HA) that represents the research question we are testing. ( something is hoing on, !=, &gt;, &lt;) | We conduct a hypothesis test under the assumption that null hypothesis is true, either via simulation(Permutation test) or theoretical test using CLT. Choose a test statistic | Compute the test statistic. | Determine the frequency distribution of the test statistic under the hypothesis. | Make a decision using this distribution as a guide as discussed in the point-4. | | If the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, we stick with the null hypothesis. If they do, then we reject the null hypothesis in the favor of the alternate hypothesis. If P value is low (Lower than significance level), we say that it is unlikely to observe the data if the null hypotheis were true, and hence reject the null hypothesis. If it is High, we won&#39;t reject the null hypothesis. | Always construct hypotheses about population parameters (e.g. population mean, μ) and not the sample statistics (e.g. sample mean) | Note that the alternative hypothesis might be one-sided (μ &lt; or &gt; the null value) or two-sided (μ≠ the null value), and the choice depends on the research question. | . Important: P Value is the probability of obtaining a value of your test statistic that is at least as extream as what ws observed, under the assumption the null hypothesis is true. It is not the probability that the null hypothesis is True. . . Note: P Value = Conditional probability of data given null hypothesis is true = P(observed or more extreme sample statistic ∣ H0 true) . Steps . Analyze the problem and state the Null Hypothesis | State the Alternate Hypothesis | Choose a test statistic and Compute the test statistic | Determine the frequency distribution of the test statistic under the hypothesis. | Calculate the P-Value for your CL based on two tail/single tail. | Make a decision. | . You can do one tailed or two tailed test based on the alternate hypothesis. . A two sided Hypothesis with significance level alpha is equivalent to a confidence interval with $CL = 1 - alpha$ | A one sided Hypothesis with significance level alpha is equivalent to a confidence interval with $CL = 1- (2* alpha)$ | . . import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt from matplotlib import rcParams # figure size in inches rcParams[&#39;figure.figsize&#39;] = 11.7,8.27 . #you can download the data from https://www.kaggle.com/spscientist/students-performance-in-exams sample_data = pd.read_csv(&quot;datasets_74977_169835_StudentsPerformance.csv&quot;) . ##sample data sample_data.head() . gender race/ethnicity parental level of education lunch test preparation course math score reading score writing score . 0 female | group B | bachelor&#39;s degree | standard | none | 72 | 72 | 74 | . 1 female | group C | some college | standard | completed | 69 | 90 | 88 | . 2 female | group B | master&#39;s degree | standard | none | 90 | 95 | 93 | . 3 male | group A | associate&#39;s degree | free/reduced | none | 47 | 57 | 44 | . 4 male | group C | some college | standard | none | 76 | 78 | 75 | . ##value counts of educatioin level sample_data[&#39;parental level of education&#39;].value_counts() . some college 226 associate&#39;s degree 222 high school 196 some high school 179 bachelor&#39;s degree 118 master&#39;s degree 59 Name: parental level of education, dtype: int64 . #test preparation sample_data[&#39;test preparation course&#39;].value_counts() . none 642 completed 358 Name: test preparation course, dtype: int64 . Comparing two independent samples . 2 groups must be independent with-in groups as well as between the groups. | If we have skewness in the sample distribution, we need more samples for hypothesis testing. | Problem Statement . We have to check whether there is a difference in the math score in students who completed the preparation course and not. . ###math scores of test completed and not completed math_score_with_test = sample_data[&#39;math score&#39;][sample_data[&#39;test preparation course&#39;]==&#39;completed&#39;] math_score_wo_test = sample_data[&#39;math score&#39;][sample_data[&#39;test preparation course&#39;]==&#39;none&#39;] . ##no of students print(&quot;No of students completed the course&quot;, len(math_score_with_test)) print(&quot;No of students not completed the course&quot;, len(math_score_wo_test)) . No of students completed the course 358 No of students not completed the course 642 . #Plotting distribution of mathscores of compeleted students sns.distplot(math_score_with_test, hist=True, kde=True, color=&#39;red&#39;, norm_hist=True, label=&quot;Completed the course&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1b38d698148&gt; . #Plotting distribution of mathscores of not compeleted students sns.distplot(math_score_wo_test, hist=True, kde=True, color=&#39;red&#39;, norm_hist=True, label=&quot;not completed the course&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1b38d5bffc8&gt; . Step-1: We can compare the mean scores of both groups. so Null Hypothesis is &quot;There is no difference in both groups&quot; H0 = There is no difference between the two groups. mu_group1 = mu_group2 mu_group1 - mu_group2 = 0 . . Step-2: Alternate Hypothesis is &quot;There is a difference between the two groups&quot; H0 = There is no difference between the two groups. mu_group1 != mu_group2 mu_group1 - mu_group2 != 0 . . Step-3: Test Statistic and Calculate the Observed Test Statistic T_obs = observed_group1_mean - observed_group2_mean = 5.617649106319291 . T_obs = math_score_with_test.mean() - math_score_wo_test.mean() T_obs . 5.617649106319291 . Step-4: Simulate the distribution using the permutation test . Permutation simulation . Let&#39;s say we have n1 elements in group1 and n2 elements in the group2. . Combine the group1, group2. | for each permutation data sample take first n1 elements as group1, rest n2 samples as group2. | calculate the test statistic | | Code . ##we can get the permutations from np.random.permutations. for i in range(5): print(np.random.permutation([1, 2, 3, 4, 5])) . [3 2 4 1 5] [4 3 5 1 2] [5 1 3 4 2] [4 2 3 1 5] [3 2 5 1 4] . data_sample = np.concatenate([math_score_with_test, math_score_wo_test]) n1 = len(math_score_with_test) dist_test_stat = [] np.random.seed(85) for i in range(1000000): out = np.random.permutation(data_sample) ##random permutation ts_cal = out[:n1].mean() - out[n1:].mean() ##getting stat difference dist_test_stat.append(ts_cal) . sns.distplot(dist_test_stat, hist=True, kde=True, color=&#39;red&#39;, norm_hist=True, label=&quot;Test Statistic distribution&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1b38b559cc8&gt; . prob = sum(np.array(dist_test_stat)&gt;=T_obs)/1000000 . prob . 1e-06 . Step-5: Calculation the P-Value . For two tailed test $ text{P Value} = 2*min([0.5, prob, 1-prob])$ . one tailed test with &#39;greater than&#39; alternate hypothesis $ text{P Value} = prob$ . one tailed test with &#39;less than&#39; alternate hypothesis $ text{P Value} = 1- (prob)$ . P_value = 2*np.min([0.5, prob, 1-prob]) print(&#39;P_value&#39;, P_value) . P_value 2e-06 . Step-6: Make a Decision: . For Significance Level of 5% (95% CL), P_value is very less so we reject the null hypothisis in favour of alternate. . . Note: In place of Test Statistic, you can use any formulation even t test stat also. . You can do all the avove with permute module of Python. . Code with permute module . from permute.core import two_sample sample_test = two_sample(x=math_score_with_test, y=math_score_wo_test, reps=100000, stat=&#39;mean&#39;, alternative=&#39;two-sided&#39;, keep_dist=True, seed=10) . sns.distplot(sample_test[2], hist=True, kde=True, color=&#39;red&#39;, norm_hist=True, label=&quot;Test Statistic distribution&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1b38f7aa648&gt; . print(&quot;observed test Statistic&quot;, sample_test[1]) print(&quot;P-Value&quot;, sample_test[0]) . observed test Statistic 5.617649106319291 P-Value 1.999980000199998e-05 . Another way to test . Get the CI of the mean(any stat) of two samples. | If those CI not overlap, there is a difference between those. | from arch.bootstrap import IIDBootstrap bs = IIDBootstrap(math_score_with_test) print(&#39;Studentized-t CI of scores of test completed students--&gt;&#39;, bs.conf_int(func=np.mean, reps=1000, method=&#39;bca&#39;, size=0.95)) . Studentized-t CI of scores of test completed students--&gt; [[68.34468215] [71.1424581 ]] . bs = IIDBootstrap(math_score_wo_test) print(&#39;Studentized-t CI of scores of test not completed students--&gt;&#39;, bs.conf_int(func=np.mean, reps=1000, method=&#39;bca&#39;, size=0.95)) . Studentized-t CI of scores of test not completed students--&gt; [[62.91883691] [65.28373942]] . There is no overlap between these 95% CI, so there is a difference. . . Tip: What if we want to check mu_group1 - mu_group2 = some_number? We can formulate that as mu_group1 - mu_group2 - some_number = 0 =&gt; mu_group1 - (mu_group2 + some_number) = 0 or (mu_group1 - some_number) - mu_group2 = 0 . Comparing two dependent samples(Paired Test): . This type of test may be needed for pre-post study on the same people or repeated measures on the same set of people. In our sample data, let&#39;s say we want to compare scores of reading and writing that are equal or not. . In the above problem, students are same in the both samples. so there is a dependency, they are not independent. | Two groups must be of same size because its a paired data.(n1=n2=n) | . . How to solve? . Get the difference(any value that you want to find) of two samples, so we will get n samples. | Do 1 sample hypothesis test to find the difference is zero or not. or use bootstrapping to get the CI and check. | . One-sample Hypothesis test using permutation . We have to check whether our mean(any stat) is centered around the zero or not. We don&#39;t have two samples to permute so we can add random positive and negative signs and we can shuffle those signs to get the hypothesis null distribution. . reading_score = sample_data[&#39;reading score&#39;] writing_score = sample_data[&#39;writing score&#39;] diff_score = reading_score - writing_score . Step-1: Null Hypothesis is &quot;difference of both scores is zero&quot; H0 = the difference between both scores is zero. mean_diff_score = 0 . . Step-2: Alternate Hypothesis is &quot;There is a difference in both scores&quot; H0 = There is a difference in both scores. mean_diff_score != 0 . . Step-3: Test Statistic and Calculate the Observed Test Statistic T_obs = mean(diff_score) . T_obs = diff_score.mean() print(T_obs) . 1.115 . Step-4: Simulate the distribution using the permutation test . one sample Permutation simulation: . Let&#39;s say we have n elements. . for M number of iterations Generate random negative and positive signs of length n. | assign those signs to the elements | calculate the statistic value. | | Code . def generate_n_random_signs(n): return 1- 2* np.random.binomial(1, 0.5, size=n) generate_n_random_signs(10)*np.random.randint(1, 10, 10) . array([ 9, 9, 4, 4, -4, -4, 9, 3, -3, 1]) . dist_test_stat = [] np.random.seed(85) n = len(diff_score) for i in tqdm(range(1000000)): out = generate_n_random_signs(n) * diff_score ts_cal = out.mean() dist_test_stat.append(ts_cal) . 100%|██████████████████████████████████████████████████████████████████████| 1000000/1000000 [08:04&lt;00:00, 2062.25it/s] . ##plotting sns.distplot(dist_test_stat, hist=True, kde=True, color=&#39;red&#39;, norm_hist=True, label=&quot;Test Statistic distribution&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1b399f9cb08&gt; . prob = sum(np.array(dist_test_stat)&gt;=T_obs)/1000000 . Step-5: Calculation the P Value . P_value = 2*np.min([0.5, prob, 1-prob]) print(&#39;P_value&#39;, P_value) . P_value 2e-06 . Step-6: Make a Decision: . For Significance Level of 5% (95% CL), P value is very less so we reject the null hypothisis in favour of alternate. . You can do all the avove with permute module of Python. . Code with permute module . from permute.core import one_sample one_sample_test = one_sample(x=diff_score, reps=100000, stat=&#39;mean&#39;, alternative=&#39;two-sided&#39;, keep_dist=False, seed=10) . print(&quot;observed test Statistic&quot;, one_sample_test[1]) print(&quot;P-Value&quot;, one_sample_test[0]) . (1.999980000199998e-05, 1.115) . Comparing N independent samples: ( Permutation ANOVA) . N groups must be independent with-in groups as well as between the groups. | If we have skewness in the sample distribution, we need more samples for hypothesis testing. | You can read about ANOVA at this or this. . . One-Way ANOVA: . Using one way ANOVA, we can compare the K groups variability. Those K groups must be independent. . Test statistic for one way ANOVA = $ sum_{k=1}^K n_k( overline{X_k} - overline{X})^2$ $n_k$ = number of samples in group k $ overline{X_k}$ = Mean of group k $ overline{X}$ = Total mean (All groups) . Except for the test statistic, everything is the same, we will permute the groups and calculate the test stat distribution. . . Steps: . Null Hypothesis - all the means are equal | Alternate Hypothesis - all means are not equal | Calculate the observed test statistic | n times: 4.1. permute the values. take the first n1 as the first group, next n2 as the second group, .. nk as kth group. 4.2. calculate the test statistic using the above formula and add to the final dist. | Plot the distribution and calculate the P-value. | . You can do above all with permute . sample_data[&#39;parental level of education&#39;].value_counts() . some college 226 associate&#39;s degree 222 high school 196 some high school 179 bachelor&#39;s degree 118 master&#39;s degree 59 Name: parental level of education, dtype: int64 . math_scores = sample_data[&#39;math score&#39;] education_groups = sample_data[&#39;parental level of education&#39;].values . Null Hypothesis = math scores of every group of education is same. Alternate Hypothesis = math scores are different in groups. . from permute.ksample import k_sample ns_oneway_anova = k_sample(x=math_scores, group=education_groups, reps=100000, stat=&#39;one-way anova&#39;, keep_dist=True, seed=10 ) . sns.distplot(ns_oneway_anova[2], hist=True, kde=True, color=&#39;red&#39;, norm_hist=True, label=&quot;Test Statistic distribution&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1b39a1d0bc8&gt; . print(&quot;observed test Statistic&quot;, ns_oneway_anova[1]) print(&quot;P-Value&quot;, ns_oneway_anova[0]) . observed test Statistic 7295.561831098111 P-Value 9.99990000099999e-06 . We can do two way anowas with permute.ksample.bivariate_k_sample .",
            "url": "https://udibhaskar.github.io/practical-ml/hypothesis%20testing/null%20hypothesis/2-sample%20test/one-sample-test/p-value/anova/2020/06/15/Hypothesis-Testing.html",
            "relUrl": "/hypothesis%20testing/null%20hypothesis/2-sample%20test/one-sample-test/p-value/anova/2020/06/15/Hypothesis-Testing.html",
            "date": " • Jun 15, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Foundations to inference Statistics",
            "content": "import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns from matplotlib import rcParams # figure size in inches rcParams[&#39;figure.figsize&#39;] = 11.7,8.27 . Sampling Distribution . . Steps for the sampling distribution . Get n random samples each of size m | Calculate the sample statistic for each random sample. | plot the sample statistics distribution | np.random.seed(10) random_population = np.random.beta(4, 5, size=1000) random_sample_population = np.random.choice(random_population, 400, False) # sns.distplot(random_sample_population, hist=True, kde=True, color=&#39;red&#39;, norm_hist=True, label=&quot;Population Dist&quot;) plt.title(&#39;Population&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x2596b4cf608&gt; . print(&#39;random population Mean --&gt;&#39;, np.mean(random_sample_population)) print(&#39;random population SD --&gt;&#39;, np.std(random_sample_population)) . random population Mean --&gt; 0.4597295869346082 random population SD --&gt; 0.16002188241803594 . Code to get sampling distribution . no_of_samples = 5000 sample_size = 50 def get_sampling_dist(population, no_of_samples, sample_size, stat): &#39;&#39;&#39; population - random sample population we have - array or list no_of_samples - number of samples (n) sample_size - size of each sample.(m) stat - sample stat to calculate. - Function &#39;&#39;&#39; sampling_dist = [] for i in range(no_of_samples): ## n samples sample = np.random.choice(population, sample_size, False) # each of size m stat_val = stat(sample) #calculating stat sampling_dist.append(stat_val) return sampling_dist sampling_dist_mean = get_sampling_dist(random_sample_population, no_of_samples, sample_size, np.mean) . ##ploting the sampling distribution. sns.distplot(sampling_dist_mean, hist=True, kde=True, color=&#39;red&#39;, norm_hist=True, label=&quot;Sampling dist of mean&quot;) plt.title(&#39;Sampling Dist of Mean&#39;) plt.xlabel(&#39;sample means&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x2596b4dea48&gt; . print(&#39;Sampling Dist Mean --&gt;&#39;, np.mean(sampling_dist_mean)) print(&#39;Sampling Dist SD --&gt;&#39;, np.std(sampling_dist_mean)) . Sampling Dist Mean --&gt; 0.46022309784271165 Sampling Dist SD --&gt; 0.020887127365585376 . We can do the above sampling distribution for any statistic value. | If we observe the above means, sampling dist mean(x_bar) is nearly equal to the population mean(mu) | We will call std of sampling dist as standard error | . Central Limit Theorem: . The distribution of sample means is nearly normal with mean = poluation mean, std = population_std/sqrt(sample_size). . . begin{align} text{Sampling Dist ~} N( mu, frac{ sigma}{ sqrt{ text{sample size}}}) end{align} . . Conditions . Sampled observations must be independent. | If we do sampling with replacement, the sample size must be less than 10% of the population. | The sample size of 30 is sufficient for most distributions. However, strongly skewed distributions can require larger sample sizes. | . Tip: We can simulate the CLT with https://gallery.shinyapps.io/CLT_mean/ . print(0.020887127365585376*np.sqrt(sample_size)) print(np.std(random_population)) . 0.14769429399712528 0.15723732430046308 . . Warning: Can the Central Limit theorem apply to any other sample statistic like median, std? -- No . Need for Confidence Interval . There will be variability in the point estimate because we can&#39;t get the exact population data in real-time. so if we tell a range of mean(any stat), it will be useful. This is called a Confidence Interval. Before going into CI, we have to know Z and t distribution, confidence level. . Z- Distribution or standard normal distribution: . begin{align} Z = frac{ x - mu}{ sigma} end{align} . . Note: mean = 0, std = 1 . standard_normal = np.random.standard_normal(size=100000) sns.distplot(standard_normal, hist=True, kde=True, color=&#39;red&#39;, norm_hist=True) plt.title(&#39;Z-Distribution&#39;) . Text(0.5, 1.0, &#39;Z-Distribution&#39;) . Confidence level . The probability that the value of a parameter falls within a specified range of values. This will be very useful when we tell an interval. We can tell like, with 95% confidence, our statistic/parameter lies between lower bound and upper bound. . . Let&#39;s calculate confidence levels for the above z distribution. For 95% confidence, (100-95)/2 = 2.5, we have to get the 2.5 percentile and (100-2.5)=97.5 percentile. . np.percentile(standard_normal, [2.5, 97.5]) . array([-1.94948191, 1.94622294]) . Our z scores lie between -1.95 and 1.95 with 95% confidence. based on above simulation( right value is 1.96, if we take more size, we will get 1.96) We can get this using (100-C)/2, 100-((100-c)/2) where C = 95 if we need 95% of confidence. . We can get these using the scipy.stats.norm.ppf function but in this function takes all the values with 0-1 only not 0-100 so 95% will become 0.95. We can get this using (1-C)/2, 1-((1-c)/2) where C = 0.95 if we need 95% of confidence. . from scipy.stats import norm def get_qnorm(CL): &#39;&#39;&#39;get the value in zdist for given CL CL - Confidence level(0-1)&#39;&#39;&#39; val = (1-CL)/2 return norm.ppf(val), norm.ppf(1-val) get_qnorm(0.95) . (-1.959963984540054, 1.959963984540054) . ##99 confidence level get_qnorm(0.99) . (-2.5758293035489004, 2.5758293035489004) . ##64 confidence level get_qnorm(0.684) . (-1.0027116650265495, 1.0027116650265495) . Student&#39;s t-distribution: . It is useful when population std is unknown. If the sample size is small, we may not get better results with the Z distribution. It is similar to the Z distribution bell-shaped curve but thicker tails than normal. Other than mean, std, it has another parameter called degree of freedom = n-1. It is wider so intervals that we get from t-dist are also wider. . . from scipy.stats import t def get_qnorm_t(CL, df): &#39;&#39;&#39;get the value in t-dist for given CL CL - Confidence level(0-1)&#39;&#39;&#39; val = (1-CL)/2 return t.ppf(val, df), t.ppf(1-val, df) get_qnorm_t(0.95, 29) . (-2.045229642132703, 2.045229642132703) . Difference between t-dist and z-dist . If we have more degrees of freedom(more samples), t-distribution will look like z-distribution. You can check that below. . for i in range(0, 1000, 50): print(&#39;95% of CL with df &#39;+str(i)+&#39; is --&gt;&#39;,get_qnorm_t(0.95, i)) . 95% of CL with df 0 is --&gt; (nan, nan) 95% of CL with df 50 is --&gt; (-2.008559109715206, 2.008559109715206) 95% of CL with df 100 is --&gt; (-1.9839715184496334, 1.9839715184496334) 95% of CL with df 150 is --&gt; (-1.9759053308869137, 1.9759053308869137) 95% of CL with df 200 is --&gt; (-1.9718962236316089, 1.9718962236316089) 95% of CL with df 250 is --&gt; (-1.9694983934204002, 1.9694983934204002) 95% of CL with df 300 is --&gt; (-1.9679030112607843, 1.9679030112607843) 95% of CL with df 350 is --&gt; (-1.9667650028635124, 1.9667650028635124) 95% of CL with df 400 is --&gt; (-1.965912343229391, 1.965912343229391) 95% of CL with df 450 is --&gt; (-1.965249664736427, 1.965249664736427) 95% of CL with df 500 is --&gt; (-1.9647198374673438, 1.9647198374673438) 95% of CL with df 550 is --&gt; (-1.964286550912067, 1.964286550912067) 95% of CL with df 600 is --&gt; (-1.9639256220427195, 1.9639256220427195) 95% of CL with df 650 is --&gt; (-1.963620322372358, 1.963620322372358) 95% of CL with df 700 is --&gt; (-1.963358711099814, 1.963358711099814) 95% of CL with df 750 is --&gt; (-1.9631320366857694, 1.9631320366857694) 95% of CL with df 800 is --&gt; (-1.9629337387277888, 1.9629337387277888) 95% of CL with df 850 is --&gt; (-1.9627588026071148, 1.9627588026071148) 95% of CL with df 900 is --&gt; (-1.9626033295371894, 1.9626033295371894) 95% of CL with df 950 is --&gt; (-1.962464242556152, 1.962464242556152) . get_qnorm(0.95) . (-1.959963984540054, 1.959963984540054) . get_qnorm_t(0.95, 50) . for i in range(0, 1000, 50): print(&#39;90% of CL with df &#39;+str(i)+&#39; is --&gt;&#39;,get_qnorm_t(0.90, i)) print(&#39;-&#39;*50) print(&#39;90% of CL in Z-dist is --&gt;&#39;, get_qnorm(0.90)) . 90% of CL with df 0 is --&gt; (nan, nan) 90% of CL with df 50 is --&gt; (-1.6759050245283318, 1.6759050245283311) 90% of CL with df 100 is --&gt; (-1.6602343260657506, 1.66023432606575) 90% of CL with df 150 is --&gt; (-1.655075500184607, 1.6550755001846063) 90% of CL with df 200 is --&gt; (-1.6525081009102696, 1.652508100910269) 90% of CL with df 250 is --&gt; (-1.6509714898126593, 1.6509714898126586) 90% of CL with df 300 is --&gt; (-1.6499486739375542, 1.6499486739375535) 90% of CL with df 350 is --&gt; (-1.6492188695371959, 1.6492188695371952) 90% of CL with df 400 is --&gt; (-1.6486719414653956, 1.648671941465395) 90% of CL with df 450 is --&gt; (-1.6482468047587875, 1.6482468047587868) 90% of CL with df 500 is --&gt; (-1.6479068539295052, 1.6479068539295045) 90% of CL with df 550 is --&gt; (-1.6476288171096811, 1.6476288171096805) 90% of CL with df 600 is --&gt; (-1.647397191759995, 1.6473971917599943) 90% of CL with df 650 is --&gt; (-1.6472012521875499, 1.6472012521875492) 90% of CL with df 700 is --&gt; (-1.6470333412605698, 1.647033341260569) 90% of CL with df 750 is --&gt; (-1.6468878462849894, 1.6468878462849887) 90% of CL with df 800 is --&gt; (-1.6467605593740848, 1.6467605593740842) 90% of CL with df 850 is --&gt; (-1.6466482638172075, 1.6466482638172069) 90% of CL with df 900 is --&gt; (-1.6465484584682117, 1.646548458468211) 90% of CL with df 950 is --&gt; (-1.6464591692544057, 1.646459169254405) -- 90% of CL in Z-dist is --&gt; (-1.6448536269514729, 1.6448536269514722) . From above, we can observe that, if df is large value( i.e n is large), t-distribution will yield similar results as z distribution. . Confidence Interval for Population Mean: . Why we need CI: There will be variability in the point estimate because we can&#39;t get the exact population data in real-time. so if we tell a range of mean, it will be useful. . . From the above CLT theorem, we know that sampling means follows a Normal distribution. we also know the properties of standard normal distribution like 68-95-99.7 rules( even we can compute for any value) i.e we can tell with 68% confidence that, mean is between mean-1*std_sampling_dist, mean+1*std_sampling_dist. . . begin{align} text{CI of Mean =} mu pm z^{*} * SE text{CI of Mean =} mu pm t^{*} * SE end{align} . from scipy.stats import norm def get_ci_mean(sampling_mean, SE, ci): &#39;&#39;&#39;Get CI for mean using z-dist sampling_mean - sample mean SE - Standard error from CLT CI - Confidence level&#39;&#39;&#39; z_temp = (1-(ci/100))/2 z = abs(norm.ppf(z_temp)) lower_bound = sampling_mean - z * SE upper_bound = sampling_mean + z * SE return lower_bound, upper_bound . n5_ci = get_ci_mean(np.mean(sampling_dist_mean), np.std(sampling_dist_mean), 95) print(&#39;95% CI is&#39;, n5_ci) . 95% CI is (0.4192850804656633, 0.5011611152197599) . from scipy.stats import t def get_ci_mean_t(sampling_mean, SE, ci, df): &#39;&#39;&#39;Get CI for mean using t-dist sampling_mean - sample mean SE - Standard error from CLT CI - Confidence level df - degrees of freedom, (n-1)&#39;&#39;&#39; t_temp = (1-(ci/100))/2 t_val = abs(t.ppf(t_temp, df)) lower_bound = sampling_mean - t_val * SE upper_bound = sampling_mean + t_val * SE return lower_bound, upper_bound . n5_ci_t = get_ci_mean_t(np.mean(sampling_dist_mean), np.std(sampling_dist_mean), 95, sample_size-1) print(&#39;95% CI is using t&#39;, n5_ci_t) . 95% CI is using t (0.41824884396920947, 0.5021973517162138) . len(sampling_dist_mean) . 5000 . . Tip: t distribution CI is wider than the Z distribution. Many times we don&#8217;t know what is the std of the population so it is better to use t distribution than z. If the sample size is larger, we can go for Z distribution(no issues if we have a large sample to analysis). . How to predict CI parameters other than mean . We know about sampling mean distribution so we can CI of mean very easily but how can we predict for median or percentile or IQR? . . There is another set of methods to do stats called Non-Parametric methods. We can use the non-parametric methods and get the CI for any value without knowing the underlying distribution. . Bootstrapping: . Bootstrap Sample is Sampling with replacement of data of same size as shown below . . Why same size? . the variation of the statistic will depend on the size of the sample. If we want to approximate this variation we need to use resamples of the same size. . Using Python . We can use np.random.choice to get the bootstrap samples. . ###code to generate a Bootstrap sample temp_population = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) print(&#39;Random Bootstrap sample from temp_population --&gt;&#39;, np.random.choice(temp_population, size=len(temp_population),replace=True)) print(&#39;Random Bootstrap sample from temp_population --&gt;&#39;, np.random.choice(temp_population, size=len(temp_population),replace=True)) print(&#39;Random Bootstrap sample from temp_population --&gt;&#39;, np.random.choice(temp_population, size=len(temp_population),replace=True)) . Random Bootstrap sample from temp_population --&gt; [ 3 10 1 8 5 8 8 3 6 5] Random Bootstrap sample from temp_population --&gt; [3 8 5 4 4 1 9 9 3 6] Random Bootstrap sample from temp_population --&gt; [10 10 4 7 2 10 9 2 7 3] . CI using Bootstrapping: . There are many ways to calculate bootstrap samples. . Percentile Method | Basic bootstrap Method or Reverse Percentile Interval | Studentized-t Bootstrap Method | Bias Corrected and accelerated | . Some notations: $ tilde{ theta}_{m}$ - statistic of Bootstrap sample m $ hat{ theta}$ - statistic of data we have. $ theta$ - statistic what we want to estimate. . Percentile Method: . steps: . Get the m bootstrap samples. | calculate the m statistics $ tilde{ theta}_{1}, tilde{ theta}_{1}, tilde{ theta}_{3} ... tilde{ theta}_{m}$ | Get the percentile values based in the how much confidance we need. Eg. for 95% CL, get 2.5 percentile and 97.5 percentile. | Code . np.random.seed(10) def get_percentile_bs_ci(data, m, stat, cl): &#39;&#39;&#39; percentile method to get BS-CI data - data we have(sample) m - number of bootstrap samples stat - statistic to find - a function cl - confidence level &#39;&#39;&#39; theta_stat = [] for i in range(m): bs_sample = np.random.choice(data, m) theta_stat.append(stat(bs_sample)) sns.distplot(theta_stat, hist=True, kde=True, color=&#39;red&#39;, norm_hist=True) lower_bound = (1-cl)/2 upper_bound = 1-lower_bound return np.percentile(theta_stat, [lower_bound*100, upper_bound*100]) . ##using above function to get bootstrap CI get_percentile_bs_ci(random_sample_population, 10000, np.mean, 0.95) . array([0.45656996, 0.46282595]) . We can ge the same thing from arch module . from arch.bootstrap import IIDBootstrap bs = IIDBootstrap(random_sample_population) . bs.conf_int(func=np.mean, reps=10000, method=&#39;percentile&#39;, size=0.95) . array([[0.44397996], [0.47526665]]) . . Important: CI from the percentile method is very narrow. If the underlying distribution is skew, it won&#8217;t work properly. so go for basic method or studentized-t method. . Basic Bootstrap Method or Reverse Percentile Interval Method: . steps: . calculate the statistic $ hat{ theta}$ on data we have. | Get the m bootstrap samples. | calculate the m statistics $ tilde{ theta}_{1}, tilde{ theta}_{1}, tilde{ theta}_{3} ... tilde{ theta}_{m}$ | Calculate the CI with above formula. . Note: It assumes distribution of $ hat{ theta}- tilde{ theta}$ and $ theta- hat{ theta}$ are simialr&lt;/b&gt; | Code . np.random.seed(10) def get_basic_bs_ci(data, m, stat, cl): &#39;&#39;&#39; Reverse Percentile Interval Method data- sample we have m - number of bootstrap samples stat - stat function to calculate cl - confidence level &#39;&#39;&#39; hat_theta = stat(data) theta_stat = [] for i in range(m): bs_sample = np.random.choice(data, m) theta_stat.append(stat(bs_sample)) #sns.distplot(theta_stat, hist=True, kde=True, color=&#39;red&#39;, norm_hist=True) lower_bound = (1-cl)/2 upper_bound = 1-lower_bound lower_bound1 = 2*hat_theta - np.percentile(theta_stat, upper_bound*100) upper_bound1 = 2*hat_theta - np.percentile(theta_stat, lower_bound*100) return lower_bound1, upper_bound1 . get_basic_bs_ci(random_sample_population, 1000, np.mean, 0.95) . (0.44972018316026047, 0.47056730107433303) . You can get the more optimized code from arch.bootstrap . from arch.bootstrap import IIDBootstrap bs = IIDBootstrap(random_sample_population) . bs.conf_int(func=np.mean, reps=10000, method=&#39;basic&#39;, size=0.95) . array([[0.44406911], [0.47499762]]) . Studentized-t Bootstrap Method: . If the distributions of $ hat{ theta}- tilde{ theta}$ and $ theta- hat{ theta}$ are not close, then the basic bootstrap confidence interval can be inaccurate. But even in this case, the distributions of $ frac{ hat{ theta}- tilde{ theta}}{SE( tilde{ theta})}$ and $ frac{ theta- hat{ theta}}{SE({ hat{ theta}})}$ could be close. hence we could use studentized bootstrap CI. . . . steps: . calculate the statistic $ hat{ theta}$ on data we have. | Get the m bootstrap samples. | For each Bootstrap sample compute the $ tilde{ theta}$ | compute $SE({ tilde{ theta}})$ | compute $q = frac{ tilde{ theta}- hat{ theta}}{SE( tilde{ theta})}$ | | Estimate $SE( hat{ theta})$ (You can directly compute or use another Bootstrap approach.) | Calculate CI using above formulation. | code . from arch.bootstrap import IIDBootstrap bs = IIDBootstrap(random_sample_population) . bs.conf_int(func=np.mean, reps=1000, method=&#39;studentized&#39;, size=0.95) . array([[0.44364941], [0.47571528]]) . Bias Corrected and accelerated bootstrap CI: . The main advantage to the BCa interval is that it corrects for bias and skewness in the distribution of bootstrap estimates. The BCa interval requires that you estimate two parameters. The bias-correction parameter, z0, is related to the proportion of bootstrap estimates that are less than the observed statistic. The acceleration parameter, a, is proportional to the skewness of the bootstrap distribution . To compute a BCa confidence interval, you estimate z0 and a and use them to adjust the endpoints of the percentile confidence interval (CI). If the bootstrap distribution is positively skewed, the CI is adjusted to the right. If the bootstrap distribution is negatively skewed, the CI is adjusted to the left. . If the statistic is biased upward (that is, if it tends to be too large), the BCa bias correction moves the endpoints to the left. If the bootstrap distribution is skewed to the right, the BCa incorporates a correction to move the endpoints even farther to the right. . You can read more about calculating z0 and a in https://projecteuclid.org/download/pdf_1/euclid.ss/1032280214 . code . from arch.bootstrap import IIDBootstrap bs = IIDBootstrap(random_sample_population) . bs.conf_int(func=np.mean, reps=1000, method=&#39;bca&#39;, size=0.95) . array([[0.44443402], [0.47456652]]) . When to use what? . If we have small sample size, basic methods like &quot;basic&quot;, &quot;percentile&quot; may give wider intervels so &#39;BCa&#39; or &#39;Studentized-t&#39; may be better. If you have skewness, go for &#39;BCa&#39;. | If we have large data, all methods may give better intervals but if we have skewness, it is better to go for &#39;BCa&#39;. | . . . references 1 https://www.stat.cmu.edu/~ryantibs/advmethods/notes/bootstrap.pdf &quot;&gt;https://en.wikipedia.org/wiki/Bootstrapping_(statistics)&#39;}}&lt;/a&gt; &quot;&gt;https://christofseiler.github.io/stats205/&#39;}}&lt;/a&gt; &quot;&gt;https://www.coursera.org/learn/inferential-statistics-intro/&#39;}}&lt;/a&gt; .",
            "url": "https://udibhaskar.github.io/practical-ml/clt/sampling/z-distribution/t-distribution/ci/confidence%20interval/bootstrapping/2020/06/07/Foundations-to-inference-Stats.html",
            "relUrl": "/clt/sampling/z-distribution/t-distribution/ci/confidence%20interval/bootstrapping/2020/06/07/Foundations-to-inference-Stats.html",
            "date": " • Jun 7, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Probability Distributions and use cases",
            "content": "Discrete distributions . import numpy as np import matplotlib.pyplot as plt import seaborn as sns from matplotlib import rcParams # figure size in inches rcParams[&#39;figure.figsize&#39;] = 11.7,8.27 . Bernoulli distribution . A Bernoulli random variable has exactly two possible outcomes. We typically label one of these outcomes a &quot;success&quot; and the other outcome a &quot;failure&quot;. We may also denote a success by 1 and a failure by 0. . The flip of a coin is modeled well by a Bernoulli distribution, as it is a single trial with a fixed nonzero probability of success (even if that probability is difficult to pin down if the coin is unfair). . Note: Probability of success = p, mean = p, Var = p(1-p) . We can silumate using np.random.random() . import numpy as np np.random.random(1) . Binomial Distribution . The binomial distribution describes a sequence of identical, independent Bernoulli trials. That is, each trial has the same probability of success, and the results of one trial do not affect any of the following trials. . let Probability of success = p . begin{align} text{Probability of k success in n trails} = P(k) &amp;= binom{n}{k} p^k (1-p)^{n-k} end{align} . Note: mean = np, Var = np(1-p) . . From above formual, we can tell given a 20 coin flips, what is the probability of getting 7 heads if getting a head is having probability of 0.35. n = 20 k = 7 p = 0.35 Then, P(7) = 0.18440118638 . We can simulate using np.random.binomial . n = 20 p = 0.35 size=1000 np.random.seed(4) vals = np.random.binomial(n, p, size) sns.distplot(vals, kde=False, rug=False, color=&#39;red&#39;, label=&quot;number of heads in simulation of 20 coin flips&quot;) plt.xlabel(&#39;No of Heads&#39;) plt.ylabel(&#39;No of times occur out of 1000 times&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x2da2f8bfa88&gt; . sns.distplot(vals, hist=False, kde=True, color=&#39;red&#39;, label=&quot;Probability of number of heads in simulation of 20 coin flips&quot;) plt.xlabel(&#39;No of Heads&#39;) plt.ylabel(&#39;Probability&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x2da301f0608&gt; . count_7 = sum(vals==7) print(&quot;count&quot;, count_7) prob = count_7/1000 print(&#39;probability&#39;, prob) . count 179 probability 0.179 . Theoritical probability we got from formula is 0.1844 and now we got 0.179. . From above simulation we can also tell for probability if every any number of heads. we got a curve which is similar to normal distribution. . . Warning: To check binomial distribution, It has to satisfy below conditions - The trials are independent. - The number of trials is fixed(n). - Each trial outcome is classified as a success or failure. - The probability of success(p) is the same for each trial. . Usecase-1 . Let&#39;s take you are working in a food delivery company. Based on previous deliveries, the probability of delivering the wrong item is 0.0085. Per day, company delivers average of 1500 items. Loss per one wrong delivery is 100rs. Calculate the maximum loss we may get? | based on above info n = 1500, p = 0.0085 . np.random.seed(5) wrong_deliveries = np.random.binomial(1500, 0.0085, 10000) . sns.distplot(wrong_deliveries, hist=False, kde=True, color=&#39;red&#39;, label=&quot;Wrong Deliveries&quot;) plt.hist(wrong_deliveries, density=True) plt.xlabel(&#39;No of deliveries&#39;) plt.ylabel(&#39;Probability&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x2da2fb3ef08&gt; . max(wrong_deliveries) . 30 . kwargs = {&#39;cumulative&#39;: True} sns.distplot(wrong_deliveries, hist_kws=kwargs, kde_kws=kwargs, label=&#39;CDF of # of wrong delivery&#39;, color=&#39;red&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x2da350e6d08&gt; . np.percentile(wrong_deliveries, 95) . 19.0 . Based on CDF or using np.percentile we can tell how many wrong orders with a probability and the we can calculate the loss. . Usecase-2 . Let&#39;s take you are working in a Manufacturing company. Based on previous data, 3% of items produced are defective. If we produce 5000 items a day, what is probabability to get a 4500 non defective items. or analyze the how many days it may needed to get 5 million non defective items? | Usecase-3 . Let&#39;s consider you are working in a tele-marketing company. Probability of converting a lead to sale is 6.5%, No of lead calls is 100 per day.. If you want to increase the revenue by some 10%, how many calls we have to make or how much conversion rate we need? How many employees we can recruit to increase the no of calls? | Poisson Distribution . The Poisson distribution is often useful for estimating the number of events in a large population over a unit of time. . Let&#39;s say, we have to calculate how many hits we will get to my website hourly. let&#39;s say probability of hit is 0.2 per hour. . We can model this even using the binomial RV if we have one hit or not in a hour but here we may get zero hits, 1 hit or some hour may give more than 1 hit. The problem with binomial is that it cannot contain more than 1 event in the unit of time (in this case, 1 hr is the unit time). The unit of time can only have 0 or 1 event. If we divid the unit of time into smaller parts, we can handle it i.e if we do n --&gt; infinite ( i.e. p --&gt; 0) in the Binomial distribution, we can model it. . The Poisson Distribution, doesn’t require you to know n or p. We are assuming n is infinitely large and p is infinitesimal. The only parameter of the Poisson distribution is the rate λ (the expected value of x). . begin{align} P(k) = frac{e^{- lambda} lambda^{k}} {k!} end{align} . Note: mean = Lambda, Var = Lambda . Usecase-1 . Let&#39;s take you are working in E-Learning company. Based on previous data, on average comapany getting 7 queries per hour. What is the probability that getting 12 queries or more in the next hour. | lamda = 7 np.random.seed(12) no_queries = np.random.poisson(lamda, size=20000) . sns.distplot(no_queries, hist=False, kde=True, color=&#39;red&#39;, label=&quot;no of queries&quot;) plt.hist(no_queries, density=True) plt.xlabel(&#39;No of queries&#39;) plt.ylabel(&#39;Probability&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x2da359304c8&gt; . print(&#39;probability&#39;, sum(no_queries&gt;=12)/len(no_queries)) . probability 0.0545 . Geometric Distribution . The geometric distribution represents the number of failures before the first success in a sequence of Bernoulli trials. . . let Probability of success = p . . begin{align} text{Probability of having exactly k failures before the first success} = P(k) = (1-p)^{k}p end{align} . . We can simulate it using np.random.geometric . Use Case-1 . A programmer has a 90% chance of finding a bug every time he compiles his code, and it takes him two hours to rewrite his code every time he discovers a bug. What is the probability that he will finish his program by the end of his workday? Assume that a workday is 8 hours and that the programmer compiles his code immediately at the beginning of the day. | Use Case-2 . 2.. In cost-benefit analyses, such as a company deciding whether to fund research trials that, if successful, will earn the company some estimated profit, the goal is to reach a success before the cost outweighs the potential gain. . Continuous distributions . Normal distribution . The normal distribution is described by two parameters μ and σ, representing the mean and standard deviation of the random variable X respectively. . . begin{align} text{Probability Density Fn} = f(x) &amp;= dfrac{1}{ sqrt{2 pi} sigma} e^{- dfrac{(x- mu)^2}{2 sigma^2}} end{align} . . We can simulate it using np.random.normal . normal_vals = np.random.normal(0, 5, 1000) . sns.distplot(normal_vals, hist=False, kde=True, color=&#39;red&#39;, label=&quot;Normal Dist&quot;) plt.hist(normal_vals, density=True) plt.legend() . &lt;matplotlib.legend.Legend at 0x2da35d863c8&gt; . . 68-95-99.7 rule . . Exponential distribution . To predict the amount of waiting time until the next event (i.e., success, failure, arrival, etc.). You can thik similar to poission distribution. In poission distribution, we can predict how many events occur in a unit of time. In Exponential distribution, amout of time needed to event occur. If the number of events per unit time follows a Poisson distribution, then the amount of time between events follows the exponential distribution. . . begin{align} text{Probability Density Fn} = f(x) &amp;= lambda e^{- lambda k} end{align} . . Warning: X ~ Exp(0.3) is to remember that 0.3 is not a time duration, but it is an event rate, which is the same as the parameter λ in a Poisson process. When rate changes, it won&#8217;t work. rate has to be constant . . We can simulate it using np.random.exponential . . Use case-1 . At a call center, calls come in every 20 minutes on average. What is the approximate probability that no calls will come in for a 30 minute period? | The time between calls can be represented by an exponential distribution with Lambda=3, since one call every 20 minutes is 3 calls per hour. we have to get the probability that at least half an hour passes between calls . np.random.seed(6) calls_time = np.random.exponential(1/3, 10000) . sum(vals&gt;0.5)/len(vals) . 0.2292 . sns.distplot(calls_time, hist=False, kde=True, color=&#39;red&#39;, label=&quot;Calls time&quot;) plt.hist(calls_time, density=True) plt.legend() . &lt;matplotlib.legend.Legend at 0x2da35d98648&gt; . Use case-2 . A computer repair customer service takes an average of 3 days repair. How long (approximately, in days) should customer has to wait to pickup repaired product with 95% confidance? | The repair time can be represented by an exponential distribution with λ=1/3, the number of repairs per day. . np.random.seed(8) manf_time = np.random.exponential(3, 10000) . manf_time . array([ 6.20086514, 10.37717835, 6.1021323 , ..., 5.30842985, 1.94993868, 3.36773582]) . n5p_value = np.percentile(manf_time, 95) n5p_value . 8.912912006371394 . The customer should wait atleast 9 days to be 95% sure that the repair has done. . Log Normal . it describes a random variable whose logarithm is normally distributed. .",
            "url": "https://udibhaskar.github.io/practical-ml/probability/distribution/bernoulli/binomial/normal/poission/geometric/lognormal/2020/06/05/Distributions.html",
            "relUrl": "/probability/distribution/bernoulli/binomial/normal/poission/geometric/lognormal/2020/06/05/Distributions.html",
            "date": " • Jun 5, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Normalization for Better Generalization and Faster Training",
            "content": "Batch Normalization . Training Deep Neural Networks is complicated by the fact that the distribution of each layer’s inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization and makes it notoriously hard to train models with saturating nonlinearities. so to overcome this, we can do a normalization after some layers as below. . . . . It calculates the batch means, std, and using those, normalizes the data then creates running mean and std which will be used in inference. One intuition about why BatchNorm works is that it removes the internal covariance shift. You can check that in the below video. . Another intuition: Batch Normalization normalizes the activations in the intermediate layers. BN primarily enables training with a larger learning rate which is cause for faster convergence and better generalization. . Larger batch size training may converge to sharp minima. If we converge to sharp minima, generalization capacity may decrease. so noise in the SGD has an important role in regularizing the NN. Similarly, Higher learning rate will bias the network towards wider minima so it will give the better generalization. But, training with a higher learning rate may cause an explosion in the updates. . If we compare the gradients between with batch normalization and without batch normalization, without batch norm network gradients are larger and heavier tailed as shown below so we can train with larger learning rates with BN. . . . Important: BN is widely adopted in computer vision but, it leads to significant performance degradation for NLP. Nowadays Layer Normalization is preferred normalization technique for NLP tasks. . Note: BN cannot be applied to online learning tasks. BN cannot applied to extremely large distributed models where the minibatches have to be small. For forward neural networks, BN can be directly applied, because each layer has a fixed number of neurons, and the mean and variance statistics of each neuron in each layer of the network can be directly stored for model prediction, but in the RNNs network, different mini-batch may have different input sequence length, it is difficult to calculate statistical information, and the test sequence length cannot be greater than the maximum training sequence length You can check the figure below from a paper, which compares the BN in CV and NLP. The differences between running mean/Variance and batch mean/variance exhibit very high variance with extreme outliers in Transformers. . . import tensorflow as tf input_layer = tf.keras.Input(shape=(6,)) bn_layer = tf.keras.layers.BatchNormalization() bn_layer_out = bn_layer(input_layer) print(&#39;Number of weights is&#39;, len(bn_layer.get_weights())) . Number of weights is 4 . If we have n features as input to the BN layer, the weight matrix we have to learn is of size (4, n), i.e. n features for each beta_initializer, gamma_initializer, moving_mean_initializer, moving_variance_initializer. Please read Tensorflow documentation to know more about Training mode, inference mode of the BN layer. It is very important to take care of the mode in BN layer. . Layer Normalization . Unlike Batch normalization, it normalized horizontally i.e. it normalizes each data point. so $ mu$, $ sigma$ not depend on the batch. layer normalization does not have to use &quot;running mean&quot; and &quot;running variance&quot;. . . It gives the better results because of the gradinets with respect to $ mu$, $ sigma$ in Layer Normalization. Derivative of $ mu$ re-centers network gradients to zero. Derivative of $ sigma$ reduces variance of network gradient, which can be seen a kind of re-scaling. . . Important: The parameters of LayerNorm, including the bias and gain, increase the risk of over-fitting, and do not work in most cases. - https://papers.nips.cc/paper/8689-understanding-and-improving-layer-normalization.pdf. You can remove these using center, scale parameters in Tensorflow. . import tensorflow as tf input_layer = tf.keras.Input(shape=(6)) norm_layer = tf.keras.layers.LayerNormalization(scale=False, center=False) norm_layer_out = norm_layer(input_layer) print(&#39;Number of weights is&#39;, len(norm_layer.get_weights())) . Number of weights is 0 . . Note: If there is no gain and bias, number of weights is zero. . import tensorflow as tf input_layer = tf.keras.Input(shape=(10,),batch_size=1) norm_layer = tf.keras.layers.LayerNormalization(scale=True, center=True) norm_layer_out = norm_layer(input_layer) print(&#39;Number of weights is&#39;, len(norm_layer.get_weights())) . Number of weights is 2 .",
            "url": "https://udibhaskar.github.io/practical-ml/nlp/batchnorm/layernorm/normalization/2020/05/10/Normalization.html",
            "relUrl": "/nlp/batchnorm/layernorm/normalization/2020/05/10/Normalization.html",
            "date": " • May 10, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Advanced Feature Extraction from Text",
            "content": "In the previous article, I discussed basic feature extraction methods like BOW, TFIDF but, these are very sparse in nature. In this tutorial, we will try to explore word vectors this gives a dense vector for each word. There are many ways to get the dense vector representation for the words. below are some of them . Co-occurrence Matrix and SVD . We can create a co-occurrence matrix of text and then get a low rank approximation of matrix to get the dense feature representation. . To create a co-occurrence matrix, you go through text setting a window size around each word. You then keep track of which words appear in that window. . lets create co-occurrence matrix with below sentences. . sent_list = [&#39;I like deeplearning.&#39;, &#39;I like NLP.&#39;, &#39;NLP is awesome.&#39;] . . with window size of 1. the co-occurrence matrix is . . . like word came in context of i 2 times in window size one. in similar way, I updated above co-occurrence matrix with all counts. . . Code . I have written a brute force version of code below. . import tensorflow as tf import numpy as np def cooccurrence_matrix(distance,sentances): &#39;&#39;&#39; Returns co-occurrence matrix of words with in a distance of occurrrence input: distance: distance between words(Window Size) sentances: documets to check ( a list ) output: co-occurance matrix in te order of list_words order words list &#39;&#39;&#39; tokenizer = tf.keras.preprocessing.text.Tokenizer() tokenizer.fit_on_texts(sentances) list_words = list(tokenizer.word_index.keys()) #print(list_words) #length of matrix needed l = len(list_words) #creating a zero matrix com = np.zeros((l,l)) #creating word and index dict dict_idx = {v:i for i,v in enumerate(list_words)} for sentence in sentances: sentence = tokenizer.texts_to_sequences([sentence])[0] tokens = [tokenizer.index_word[i] for i in sentence] #tokens= sentence.split() for pos,token in enumerate(tokens): #if eord is in required words if token in list_words: #start index to check any other word occure or not start=max(0,pos-distance) #end index end=min(len(tokens),pos+distance+1) for pos2 in range(start,end): #if same position if pos2==pos: continue # if same word if token == tokens[pos2]: continue #if word found is in required words if tokens[pos2] in list_words: #index of word parent row = dict_idx[token] #index of occurance word col = dict_idx[tokens[pos2]] #adding value to that index com[row,col] = com[row,col] + 1 return com, list_words . coo = cooccurrence_matrix(1, sent_list) print(coo[1]) print(coo[0]) . [&#39;i&#39;, &#39;like&#39;, &#39;nlp&#39;, &#39;deeplearning&#39;, &#39;is&#39;, &#39;awesome&#39;] [[0. 2. 0. 0. 0. 0.] [2. 0. 1. 1. 0. 0.] [0. 1. 0. 0. 1. 0.] [0. 1. 0. 0. 0. 0.] [0. 0. 1. 0. 0. 1.] [0. 0. 0. 0. 1. 0.]] . Now we can use SVD to get low rank approximation matrix(This will give dense matrix) . from sklearn.decomposition import TruncatedSVD tsvd = TruncatedSVD(n_components=3, n_iter=10, random_state=32 ) dense_vector = tsvd.fit_transform(coo[0], ) dense_vector . array([[ 1.94649798e+00, 2.73880515e-15, -2.49727487e-01], [-2.40633313e-15, 2.43040910e+00, -2.56144970e-01], [ 1.20300191e+00, 1.58665133e-15, 4.04067562e-01], [ 9.73248989e-01, 1.21830556e-15, -1.24863743e-01], [ 7.73781546e-16, 5.73741760e-01, 1.08504750e+00], [ 2.29752921e-01, 3.09635046e-16, 5.28931305e-01]]) . print(&quot;Vector of &quot;, &quot;&#39;&quot; , coo[1][1], &quot;&#39;&quot;, &quot;is &quot;, dense_vector[1]) . Vector of &#39; like &#39; is [-2.40633313e-15 2.43040910e+00 -2.56144970e-01] . Word2Vec . I think, there are many articles and videos regarding the Mathematics and Theory of Word2Vec. So, I am giving some links to explore and I will try to explain code to train the custom Word2Vec. Please check the resources below. . . You can read a good blog here . . Please watch the above videos or read the above blog before going into the coding part. . Word2Vec using Gensim . We can train word2vec using gensim module with CBOW or Skip-Gram ( Hierarchical Softmax/Negative Sampling). It is one of the efficient ways to train word vectors. I am training word vectors using gensim, using IMDB reviews as a data corpus to train. In this, I am not training the best word vectors, only training for 10 iterations. . . To train gensim word2vec module, we can give a list of sentences or a file a corpus file in LineSentence format. Here I am creating a list of sentences from my corpus. If you have huge data, please try to use LineSentence format to efficiently train your word vectors. . ##getting sentence wise data list_sents = [nltk.word_tokenize(sent) for sent_tok in data_imdb.review for sent in nltk.sent_tokenize(sent_tok)] . Training gensim word2vec as below . ##import gensim from gensim.models import Word2Vec ##word2vec model ##this may take some time to execute. word2vec_model = Word2Vec(list_sents,##list of sentences, if you don;t have all the data in RAM, you can give file name to corpus_file size=50, ##output size of word emebedding window=4, ##window size min_count=1, ## ignors all the words with total frquency lower than this workers=5, ##number of workers to use sg=1, ## skip gram hs=0, ## 1 --&gt; hierarchical, 0 --&gt; Negative sampling negative=5, ##How many negative samples alpha=0.03, ##The initial learning rate min_alpha=0.0001, ##Learning rate will linearly drop to min_alpha as training progresses. seed = 54, ##random seed iter=10, compute_loss=True)##number of iterations . You can get word vectors as below . ##getting a word vector word2vec_model.wv[&#39;movie&#39;] . You can get most similar positive words for any given word as below . ##getting most similar positive words word2vec_model.wv.most_similar(positive=&#39;movie&#39;) . You can save your model as below . ##saving the model word2vec_model.save(&#39;w2vmodel/w2vmodel&#39;) . You can get the total notebook in the below GitHub link . github:https://github.com/UdiBhaskar/Natural-Language-Processing/blob/master/Feature%20Extraction%20Methods/Advanced%20feature%20extraction%20-%20W2V/W2V_using_Gensim.ipynb . Word2Vec using Tensorflow ( Skip-Gram, Negative Sampling) . In the negative sampling, we will get a positive pair of skip-grams and for every positive pair, we will generate n number of negative pairs. I used only 10 negative pairs. In the paper, they suggesting around 25. Now we will use these positive and negative pairs and try to create a classifier that differentiates both positive and negative samples. While doing this, we will learn the word vectors. We have to train a classifier that differentiates positive sample and negative samples, while doing this we will learn the word embedding. Classifier looks like below image . . . . The above model takes two inputs center word, context word and, model output is one if those two words occur within a window size else zero. . Preparing the data . We have to generate the skip-gram pairs and negative samples. We can do that easily using tf.keras.preprocessing.sequence.skipgrams. This also takes a probability table(sampling table), in which we can give the probability of that word to utilize in the negative samples i.e. we can make probability low for the most frequent words and high probability for the least frequent words while generating negative samples. . Converted total words into the number sequence. Numbers are given in descending order of frequency. . ##to use tf.keras.preprocessing.sequence.skipgrams, we have to encode our sentence to numbers. so used Tokenizer class tokenizer = tf.keras.preprocessing.text.Tokenizer() tokenizer.fit_on_texts(list_sents) seq_texts = tokenizer.texts_to_sequences(list_sents) ##list of list+ . If we create total samples at once, it may take so much RAM and that gives the resource exhaust error. so created a generator function which generates the values batchwise. . ##Skipgram with Negativive sampling generator ##for generating the skip gram negative samples we can use tf.keras.preprocessing.sequence.skipgrams and #internally uses sampling table so we need to generate sampling table with tf.keras.preprocessing.sequence.make_sampling_table sampling_table_ns = tf.keras.preprocessing.sequence.make_sampling_table(size=len(tokenizer.word_index)+1, sampling_factor=1e-05) def generate_sgns(): ##loop through all the sequences for seq in seq_texts: generated_samples, labels = tf.keras.preprocessing.sequence.skipgrams(sequence=seq, vocabulary_size=len(tokenizer.word_index)+1, window_size=3, negative_samples=10, sampling_table=sampling_table_ns) length_samples = len(generated_samples) for i in range(length_samples): ##centerword, context word, label yield [generated_samples[i][0]], [generated_samples[i][1]], [labels[i]] ##creating the tf dataset tfdataset_gen = tf.data.Dataset.from_generator(generate_sgns, output_types=(tf.int64, tf.int64, tf.int64)) tfdataset_gen = tfdataset_gen.repeat().batch(2048).prefetch(tf.data.experimental.AUTOTUNE) . Creating Model . ##fixing numpy RS np.random.seed(42) ##fixing tensorflow RS tf.random.set_seed(32) ##python RS rn.seed(12) tf.keras.backend.clear_session() ##model def getSGNS(): center_word_input= Input(shape=(1,), name=&quot;center_word_input&quot;) context_word_input= Input(shape=(1,), name=&quot;context_word_input&quot;) ##i am initilizing randomly. But you can use predefined embeddings. embedd_layer = Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, embeddings_initializer=tf.keras.initializers.RandomUniform(seed=45), name=&quot;Embedding_layer&quot;) #center word embedding center_wv = embedd_layer(center_word_input) #context word embedding context_wv = embedd_layer(context_word_input) #dot product dot_out = Dot(axes=2, name=&quot;dot_between_center_context&quot;)([center_wv, context_wv]) dot_out = Reshape((1,), name=&quot;reshaping&quot;)(dot_out) final_out = Dense(1, activation=&#39;sigmoid&#39;, kernel_initializer=tf.keras.initializers.glorot_uniform(seed=54), name=&quot;output_layer&quot;)(dot_out) basic_w2v = Model(inputs=[center_word_input, context_word_input], outputs=final_out, name=&quot;sgns_w2v&quot;) return basic_w2v sgns_w2v = getSGNS() . Training . ##training ##optimizer optimizer = tf.keras.optimizers.Adam(learning_rate=0.005) ##train step function to train @tf.function def train_step(input_center, input_context, output_vector, loss_fn): with tf.GradientTape() as tape: #forward propagation output_predicted = sgns_w2v(inputs=[input_center, input_context], training=True) #loss loss = loss_fn(output_vector, output_predicted) #getting gradients gradients = tape.gradient(loss, sgns_w2v.trainable_variables) #applying gradients optimizer.apply_gradients(zip(gradients, sgns_w2v.trainable_variables)) return loss, gradients ##number of epochs no_iterations=100000 ##metrics # Even if you use .fit method, it alsocalculates batchwise loss/metric and aggregates those. train_loss = tf.keras.metrics.Mean(name=&#39;train_loss&#39;) #tensorboard file writers wtrain = tf.summary.create_file_writer(logdir=&#39;/content/drive/My Drive/word2vec/logs/w2vns/train&#39;) ##creating a loss object for this classification problem loss_function = tf.keras.losses.BinaryCrossentropy(from_logits=False, reduction=&#39;auto&#39;) ##check point to save checkpoint_path = &quot;/content/drive/My Drive/word2vec/checkpoints/w2vNS/train&quot; ckpt = tf.train.Checkpoint(optimizer=optimizer, model=sgns_w2v) ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=3) counter = 0 #training anf validating for in_center, in_context, out_label in tfdataset_gen: #train step loss_, gradients = train_step(in_center, in_context, out_label, loss_function) #adding loss to train loss train_loss(loss_) counter = counter + 1 ##tensorboard with tf.name_scope(&#39;per_step_training&#39;): with wtrain.as_default(): tf.summary.scalar(&quot;batch_loss&quot;, loss_, step=counter) with tf.name_scope(&quot;per_batch_gradients&quot;): with wtrain.as_default(): for i in range(len(sgns_w2v.trainable_variables)): name_temp = sgns_w2v.trainable_variables[i].name tf.summary.histogram(name_temp, gradients[i], step=counter) if counter%100 == 0: #printing template = &#39;&#39;&#39;Done {} iterations, Loss: {:0.6f}&#39;&#39;&#39; print(template.format(counter, train_loss.result())) if counter%200 == 0: ckpt_save_path = ckpt_manager.save() print (&#39;Saving checkpoint for iteration {} at {}&#39;.format(counter+1, ckpt_save_path)) train_loss.reset_states() if counter &gt; no_iterations: break . You can check total code and results in my GitHub link below. . github:https://github.com/UdiBhaskar/Natural-Language-Processing/blob/master/Feature%20Extraction%20Methods/Advanced%20feature%20extraction%20-%20W2V/W2V_Tensorflow_Negative_Sampling.ipynb . Saved the model into gensim Word2Vec format and loaded . save_word2vec_format_dict(binary=True, fname=&#39;w2vns.bin&#39;, total_vec=len(word_vectors_dict), vocab=model_gensim.vocab, vectors=model_gensim.vectors) model_gensim = gensim.models.keyedvectors.Word2VecKeyedVectors.load_word2vec_format(&#39;w2vns.bin&#39;, binary=True) . . Important: Negative Sampling is a simplified version of Noise Contrastive Estimation. NCE guarantees approximation to softmax, Negative Sampling doesn’t. You can read this in paper/blog. . Word2Vec using Tensorflow (Skip-Gram, NCE) . Let&#39;s take a which gives the score to each pair of the skip-grams, we will try to maximize the (score of positive pairs to the word - score of negative pairs) to the word. We can do that directly by optimizing the tf.nn.nce_loss. Please try to read the documentation. It takes a positive pair, weight vectors and then generates the negative pairs based on sampled_values, and gives the loss. . Preparing the Data . We have to generate a positive pair of skip-grams, we can do it in a similar way as above. Created a pipeline to generate batchwise data as below. . ##getting sentence wise data list_sents = [nltk.word_tokenize(sent) for sent_tok in data_imdb.review for sent in nltk.sent_tokenize(sent_tok)] ##to use tf.keras.preprocessing.sequence.skipgrams, we have to encode our sentence to numbers. so used Tokenizer class tokenizer = tf.keras.preprocessing.text.Tokenizer() tokenizer.fit_on_texts(list_sents) seq_texts = tokenizer.texts_to_sequences(list_sents) ##list of list def generate_sgns(): for seq in seq_texts: generated_samples, labels = tf.keras.preprocessing.sequence.skipgrams(sequence=seq, vocabulary_size=len(tokenizer.word_index)+1, window_size=2, negative_samples=0) length_samples = len(generated_samples) for i in range(length_samples): yield [generated_samples[i][0]], [generated_samples[i][1]] ##creating the tf dataset tfdataset_gen = tf.data.Dataset.from_generator(generate_sgns, output_types=(tf.int64, tf.int64)) tfdataset_gen = tfdataset_gen.repeat().batch(1024).prefetch(tf.data.experimental.AUTOTUNE) . Creating Model . I created a model word2vecNCS which takes a center word, context word and give NCE loss. You can check that below. . class word2vecNCS(Model): def __init__(self, vocab_size, embed_size, num_sampled, **kwargs): &#39;&#39;&#39;NCS Word2Vec vocab_size: Size of vocabulary you have embed_size: Embedding size needed num_sampled: No of negative sampled to generate&#39;&#39;&#39; super(word2vecNCS, self).__init__(**kwargs) self.vocab_size = vocab_size self.embed_size = embed_size self.num_sampled = num_sampled ##embedding layer self.embed_layer = Embedding(input_dim=vocab_size, output_dim=embed_size,embeddings_initializer=tf.keras.initializers.RandomUniform(seed=32)) ##reshing layer self.reshape_layer = Reshape((self.embed_size,)) def build(self, input_shape): ##weights needed for nce loss self.nce_weight = self.add_weight(shape=(self.vocab_size, self.embed_size), initializer=tf.keras.initializers.TruncatedNormal(mean=0, stddev= (1/self.embed_size**0.5)), trainable=True, name=&quot;nce_weight&quot;) #biases needed nce loss self.nce_bias = self.add_weight(shape=(self.vocab_size), initializer=&quot;zeros&quot;, trainable=True, name=&quot;nce_bias&quot;) def call(self, input_center_word, input_context_word): &#39;&#39;&#39; input_center_word: center word input_context_word: context word&#39;&#39;&#39; ##giving center word and getting the embedding embedd_out = self.embed_layer(input_center_word) ##rehaping embedd_out = self.reshape_layer(embedd_out) ##calculating nce loss nce_loss = tf.reduce_sum(tf.nn.nce_loss(weights=self.nce_weight, biases=self.nce_bias, labels=input_context_word, inputs=embedd_out, num_sampled=self.num_sampled, num_classes=self.vocab_size)) return nce_loss . Training . ##training ##optimizer optimizer = tf.keras.optimizers.Adam(learning_rate=0.005) sgncs_w2v = word2vecNCS(len(tokenizer.word_index)+1, 100, 32, name=&quot;w2vNCE&quot;) ##train step function to train @tf.function def train_step(input_center, input_context): with tf.GradientTape() as tape: #forward propagation loss = sgncs_w2v(input_center, input_context) #getting gradients gradients = tape.gradient(loss, sgncs_w2v.trainable_variables) #applying gradients optimizer.apply_gradients(zip(gradients, sgncs_w2v.trainable_variables)) return loss, gradients ##number of epochs no_iterations=10000 ##metrics # Even if you use .fit method, it alsocalculates batchwise loss/metric and aggregates those. train_loss = tf.keras.metrics.Mean(name=&#39;train_loss&#39;) #tensorboard file writers wtrain = tf.summary.create_file_writer(logdir=&#39;/content/drive/My Drive/word2vec/logs/w2vncs/train&#39;) ##check point to save checkpoint_path = &quot;/content/drive/My Drive/word2vec/checkpoints/w2vNCS/train&quot; ckpt = tf.train.Checkpoint(optimizer=optimizer, model=sgncs_w2v) ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=3) counter = 0 #training anf validating for in_center, in_context in tfdataset_gen: #train step loss_, gradients = train_step(in_center, in_context) #adding loss to train loss train_loss(loss_) counter = counter + 1 ##tensorboard with tf.name_scope(&#39;per_step_training&#39;): with wtrain.as_default(): tf.summary.scalar(&quot;batch_loss&quot;, loss_, step=counter) with tf.name_scope(&quot;per_batch_gradients&quot;): with wtrain.as_default(): for i in range(len(sgncs_w2v.trainable_variables)): name_temp = sgncs_w2v.trainable_variables[i].name tf.summary.histogram(name_temp, gradients[i], step=counter) if counter%100 == 0: #printing template = &#39;&#39;&#39;Done {} iterations, Loss: {:0.6f}&#39;&#39;&#39; print(template.format(counter, train_loss.result())) if counter%200 == 0: ckpt_save_path = ckpt_manager.save() print (&#39;Saving checkpoint for iteration {} at {}&#39;.format(counter+1, ckpt_save_path)) train_loss.reset_states() if counter &gt; no_iterations : break . You can check total code and results in my GitHub link below. . github:https://github.com/UdiBhaskar/Natural-Language-Processing/blob/master/Feature%20Extraction%20Methods/Advanced%20feature%20extraction%20-%20W2V/W2V_Tensorflow_NCE.ipynb . Fast-text Embedding (Sub-Word Embedding) . Instead of feeding individual words into the Neural Network, FastText breaks words into several n-grams (sub-words). For instance, tri-grams for the word where is &lt;wh, whe, her, ere, re&gt; and the special sequence &lt;where&gt;. Note that the sequence, corresponding to the word her is different from the tri-gram her from the word where. Because of these subwords, we can get embedding for any word we have even it is a misspelled word. Try to read this paper. . . We can train these vectors using the gensim or fastText official implementation. Trained fastText word embedding with gensim, you can check that below. It&#39;s a single line of code similar to Word2vec. . ##FastText module from gensim.models import FastText gensim_fasttext = FastText(sentences=list_sents, sg=1, ##skipgram hs=0, #negative sampling min_count=4, ##min count of any vocab negative=10, ##no of negative samples iter=15, ##no of iterations size=100, ##dimentions of word window=3, ##window size to get the skipgrams seed=34) . You can get the total code in the below GitHub . github:https://github.com/UdiBhaskar/Natural-Language-Processing/blob/master/Feature%20Extraction%20Methods/Advanced%20feature%20extraction%20-%20W2V/fasttext_Training.ipynb . Pre-Trained Word Embedding . We can get pre-trained word embedding that was trained on huge data by Google, Stanford NLP, Facebook. . Google Word2Vec . You can download google&#39;s pretrained wordvectors trained on Google news data from this link. You can load the vectors as gensim model like below . googlew2v_model = gensim.models.KeyedVectors.load_word2vec_format(&#39;GoogleNews-vectors-negative300.bin&#39;, binary=True) . GloVe Pretrained Embeddings . You can download the glove embedding from this link. There are some differences between Google Word2vec save format and GloVe save format. We can convert Glove format to google format and then load that using gensim as below. . from gensim.scripts.glove2word2vec import glove2word2vec glove2word2vec(glove_input_file=&quot;glove.42B.300d.txt&quot;, word2vec_output_file=&quot;w2vstyle_glove_vectors.txt&quot;) glove_model = gensim.models.KeyedVectors.load_word2vec_format(&quot;w2vstyle_glove_vectors.txt&quot;, binary=False) . FastText Pretrained Embeddings . You can get the fasttext word embeedings from this link. You can use fasttext python api or gensim to load the model. I am using gensim. . from gensim.models import FastText fasttext_model = FastText.load_fasttext_format(&quot;/content/cc.en.300.bin&quot;) . . References: . gensim documentation | https://fasttext.cc/ | CS7015 - IIT Madras | https://lilianweng.github.io/lil-log/2017/10/15/learning-word-embedding.html | https://arxiv.org/abs/1410.8251 | https://ruder.io/word-embeddings-softmax/ |",
            "url": "https://udibhaskar.github.io/practical-ml/nlp/feature%20extraction/word2vec/fasttext/2020/03/16/Advanced-Feature-Extraction.html",
            "relUrl": "/nlp/feature%20extraction/word2vec/fasttext/2020/03/16/Advanced-Feature-Extraction.html",
            "date": " • Mar 16, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Basic Feature Extraction Methods",
            "content": "Document Term Matrix . It is a matrix with rows contains unique documents and the column contain the unique words/tokens. Let&#39;s take sample documents and store them in the sample_documents. . sample_documents = [&#39;This is the NLP notebook&#39;, &#39;This is basic NLP. NLP is easy&#39;, &#39;NLP is awesome&#39;] . In the above sample_documents, we have 3 documents and 8 unique words. The Document Term matrix contains 3 rows and 8 columns as below. . There are many ways to determine the value(content) in the above matrix. I will discuss some of the ways below. After filling those values, we can use each row as vector representation of documents. . Bag of Words . In this, we will fill with the number of times that word occurred in the same document. . . . . If you check the above matrix, &quot;nlp&quot; occurred two times in the document-2 so value corresponding to that is 2. If it occurs n times in the document, the value corresponding is n. We can do the same in the using CountVectorizer in sklearn. . ##import count vectorizer from sklearn.feature_extraction.text import CountVectorizer #creating CountVectorizer instance bow_vec = CountVectorizer(lowercase=True, ngram_range=(1,1), analyzer=&#39;word&#39;) #fitting with our data bow_vec.fit(sample_documents) #transforming the data to the vector sample_bow_metrix = bow_vec.transform(sample_documents) #printing print(&quot;Unique words --&gt;&quot;, bow_vec.get_feature_names()) print(&quot;BOW Matrix --&gt;&quot;,sample_bow_metrix.toarray()) print(&quot;vocab to index dict --&gt;&quot;, bow_vec.vocabulary_) . Unique words --&gt; [&#39;awesome&#39;, &#39;basic&#39;, &#39;easy&#39;, &#39;is&#39;, &#39;nlp&#39;, &#39;notebook&#39;, &#39;the&#39;, &#39;this&#39;] BOW Matrix --&gt; [[0 0 0 1 1 1 1 1] [0 1 1 2 2 0 0 1] [1 0 0 1 1 0 0 0]] vocab to index dict --&gt; {&#39;this&#39;: 7, &#39;is&#39;: 3, &#39;the&#39;: 6, &#39;nlp&#39;: 4, &#39;notebook&#39;: 5, &#39;basic&#39;: 1, &#39;easy&#39;: 2, &#39;awesome&#39;: 0} . . Note: How CountVectorizer gets the unique words? -- It first splits the documents into words and then it gets the unique words. CountVectorizer uses token_pattern or tokenizer, we can give our custom tokenization algorithm to get words from a sentence. Please try to read the documentation of the sklearn to know more about it. . We can also get the n-gram words as vocab. please check the below code. That was written for unigrams and bi-grams. . Note: N-grams are simply all combinations of adjacent words of length n that you can find in your source text. . #creating CountVectorizer instance with ngram_range = (1,2) i.e uni-gram and bi-gram bow_vec = CountVectorizer(lowercase=True, ngram_range=(1,2), analyzer=&#39;word&#39;) #fitting with our data bow_vec.fit(sample_documents) #transforming the data to the vector sample_bow_metrix = bow_vec.transform(sample_documents) #printing print(&quot;Unique words --&gt;&quot;, bow_vec.get_feature_names()) print(&quot;BOW Matrix --&gt;&quot;,sample_bow_metrix.toarray()) print(&quot;vocab to index dict --&gt;&quot;, bow_vec.vocabulary_) . Unique words --&gt; [&#39;awesome&#39;, &#39;basic&#39;, &#39;basic nlp&#39;, &#39;easy&#39;, &#39;is&#39;, &#39;is awesome&#39;, &#39;is basic&#39;, &#39;is easy&#39;, &#39;is the&#39;, &#39;nlp&#39;, &#39;nlp is&#39;, &#39;nlp nlp&#39;, &#39;nlp notebook&#39;, &#39;notebook&#39;, &#39;the&#39;, &#39;the nlp&#39;, &#39;this&#39;, &#39;this is&#39;] BOW Matrix --&gt; [[0 0 0 0 1 0 0 0 1 1 0 0 1 1 1 1 1 1] [0 1 1 1 2 0 1 1 0 2 1 1 0 0 0 0 1 1] [1 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0]] vocab to index dict --&gt; {&#39;this&#39;: 16, &#39;is&#39;: 4, &#39;the&#39;: 14, &#39;nlp&#39;: 9, &#39;notebook&#39;: 13, &#39;this is&#39;: 17, &#39;is the&#39;: 8, &#39;the nlp&#39;: 15, &#39;nlp notebook&#39;: 12, &#39;basic&#39;: 1, &#39;easy&#39;: 3, &#39;is basic&#39;: 6, &#39;basic nlp&#39;: 2, &#39;nlp nlp&#39;: 11, &#39;nlp is&#39;: 10, &#39;is easy&#39;: 7, &#39;awesome&#39;: 0, &#39;is awesome&#39;: 5} . TF-IDF . In this, we will fill with TF*IDF. . Term Frequency . begin{align} TF_K = frac{ text{No of times word K occurred in that document}}{ text{Total number of words in that document}} end{align} . Note: TF of a word is only dependent on a particular document. It won&#8217;t depend on the total corpus of documents. TF value of word changes from document to document . Inverse Document Frequency . begin{align} IDF_K = log( frac{ text{Total number of documents}}{ text{Number of documents with word K}} ) end{align} . Note: IDF of a word dependent on total corpus of documents. IDF value of word is constant for total corpus. . You can think IDF as the information content of the word. . begin{align} text{Information Content} = -log( text{Probability of Word}) text{Probability of Word K} = frac{ text{Number of documents with word K}}{ text{Total number of documents}} end{align} We can calculate the TFIDF vectors using TfidfVectorizer in sklearn. . from sklearn.feature_extraction.text import TfidfVectorizer #creating TfidfVectorizer instance tfidf_vec = TfidfVectorizer() #fitting with our data tfidf_vec.fit(sample_documents) #transforming the data to the vector sample_tfidf_metrix = tfidf_vec.transform(sample_documents) #printing print(&quot;Unique words --&gt;&quot;, tfidf_vec.get_feature_names()) print(&quot;TFIDF Matrix --&gt;&quot;, &#39; n&#39;,sample_tfidf_metrix.toarray()) print(&quot;vocab to index dict --&gt;&quot;, tfidf_vec.vocabulary_) . Unique words --&gt; [&#39;awesome&#39;, &#39;basic&#39;, &#39;easy&#39;, &#39;is&#39;, &#39;nlp&#39;, &#39;notebook&#39;, &#39;the&#39;, &#39;this&#39;] TFIDF Matrix --&gt; [[0. 0. 0. 0.32630952 0.32630952 0.55249005 0.55249005 0.42018292] [0. 0.43157129 0.43157129 0.50978591 0.50978591 0. 0. 0.32822109] [0.76749457 0. 0. 0.45329466 0.45329466 0. 0. 0. ]] vocab to index dict --&gt; {&#39;this&#39;: 7, &#39;is&#39;: 3, &#39;the&#39;: 6, &#39;nlp&#39;: 4, &#39;notebook&#39;: 5, &#39;basic&#39;: 1, &#39;easy&#39;: 2, &#39;awesome&#39;: 0} . With the TfidfVectorizer also we can get the n-grams and we can give our own tokenization algorithm. . What if we have so much vocab in our corpus? . If we have many unique words, our BOW/TFIDF vectors will be very high dimensional that may cause curse of dimensionality problem. We can solve this with the below methods. . Limiting the number of vocab in BOW/TFIDF . In CountVectorize, we can do this using max_features, min_df, max_df. You can use vocabulary parameter to get specific words only. Try to read the documentation of CountVectorize to know better about those. You can check the sample code below. . #creating CountVectorizer instance, limited to 4 features only bow_vec = CountVectorizer(lowercase=True, ngram_range=(1,1), analyzer=&#39;word&#39;, max_features=4) #fitting with our data bow_vec.fit(sample_documents) #transforming the data to the vector sample_bow_metrix = bow_vec.transform(sample_documents) #printing print(&quot;Unique words --&gt;&quot;, bow_vec.get_feature_names()) print(&quot;BOW Matrix --&gt;&quot;,sample_bow_metrix.toarray()) print(&quot;vocab to index dict --&gt;&quot;, bow_vec.vocabulary_) . Unique words --&gt; [&#39;awesome&#39;, &#39;is&#39;, &#39;nlp&#39;, &#39;this&#39;] BOW Matrix --&gt; [[0 1 1 1] [0 2 2 1] [1 1 1 0]] vocab to index dict --&gt; {&#39;this&#39;: 3, &#39;is&#39;: 1, &#39;nlp&#39;: 2, &#39;awesome&#39;: 0} . You can do similar thing with TfidfVectorizer with same parameters. Please read the documentation. . Some of the problems with the CountVectorizer and TfidfVectorizer . If we have a large corpus, vocabulary will also be large and for fit function, you have to get all documents into RAM. This may be impossible if you don&#39;t have sufficient RAM. | building the vocab requires a full pass over the dataset hence it is not possible to fit text classifiers in a strictly online manner. | After the fit, we have to store the vocab dict, which takes so much memory. If we want to deploy in memory-constrained environments like amazon lambda, IoT devices, mobile devices, etc.., these maybe not useful. | . . Important: We can solve the first problem with an iterator over the total data and building the vocab then, using that vocab, we can create the BOW matrix in the sparse format and then TFIDF vectors using TfidfTransformer. The sparse matrix won&#8217;t take much space so, we can store the BOW sparse matrix in our RAM to create the TFIDF sparse matrix. . I have written a sample code to do that for the same data. I have iterated over the data, created vocab, and using that vocab, created BOW. We can write a much more optimized version of the code, This is just a sample to show. . ##for tokenization import nltk #vertical stack of sparse matrix from scipy.sparse import vstack #vocab set vocab_set = set() #looping through the points(for huge data, you will get from your disk/table) for data_point in sample_documents: #getting words for word in nltk.tokenize.word_tokenize(data_point): if word.isalpha(): vocab_set.add(word.lower()) vectorizer_bow = CountVectorizer(vocabulary=vocab_set) bow_data = [] for data_point in sample_documents: # use a generator ##if we give the vocab, there will be no data lekage for fit_transform so we can use that bow_data.append(vectorizer_bow.fit_transform([data_point])) final_bow = vstack(bow_data) print(&quot;Unique words --&gt;&quot;, vectorizer_bow.get_feature_names()) print(&quot;BOW Matrix --&gt;&quot;,final_bow.toarray()) print(&quot;vocab to index dict --&gt;&quot;, vectorizer_bow.vocabulary_) . Unique words --&gt; [&#39;awesome&#39;, &#39;basic&#39;, &#39;easy&#39;, &#39;is&#39;, &#39;nlp&#39;, &#39;notebook&#39;, &#39;the&#39;, &#39;this&#39;] BOW Matrix --&gt; [[0 0 0 1 1 1 1 1] [0 1 1 2 2 0 0 1] [1 0 0 1 1 0 0 0]] vocab to index dict --&gt; {&#39;awesome&#39;: 0, &#39;basic&#39;: 1, &#39;easy&#39;: 2, &#39;is&#39;: 3, &#39;nlp&#39;: 4, &#39;notebook&#39;: 5, &#39;the&#39;: 6, &#39;this&#39;: 7} . The above result is similar to the one we printed while doing the BOW, you can check that. . . Using the above BOW sparse matrix and the TfidfTransformer, we can create the TFIDF vectors. you can check below code. . #importing from sklearn.feature_extraction.text import TfidfTransformer #instanciate the class vec_tfidftransformer = TfidfTransformer() #fit with the BOW sparse data vec_tfidftransformer.fit(final_bow) vec_tfidf = vec_tfidftransformer.transform(final_bow) print(vec_tfidf.toarray()) . [[0. 0. 0. 0.32630952 0.32630952 0.55249005 0.55249005 0.42018292] [0. 0.43157129 0.43157129 0.50978591 0.50978591 0. 0. 0.32822109] [0.76749457 0. 0. 0.45329466 0.45329466 0. 0. 0. ]] . The above result is similar to the one we printed while doing the TFIDF, you can check that. . . Important: Other than our own iterator/generator, if we have data in one file or multiple files, we can directly give input parameter as file/filename and while fit function, we can give file path. Please read the documentation. . Another way to solve all the above problems are hashing. We can convert a word into fixed index number using the hash function. so, there will be no training process to get the vocabulary and no need to save the vocab. It was implemented in sklearn with HashingVectorizer. In HashingVectorizer, you have to mention number of features you need, by default it takes $2^{20}$. below you can see some code to use HashingVectorizer. . #importing the hashvectorizer from sklearn.feature_extraction.text import HashingVectorizer #instanciating the HashingVectorizer hash_vectorizer = HashingVectorizer(n_features=5, norm=None, alternate_sign=False) #transforming the data, No need to fit the data because, it is stateless hash_vector = hash_vectorizer.transform(sample_documents) #printing the output print(&quot;Hash vectors --&gt;&quot;,hash_vector.toarray()) . Hash vectors --&gt; [[0. 1. 3. 1. 0.] [0. 1. 5. 1. 0.] [0. 0. 3. 0. 0.]] . . Note: You can normalize your vectors using norm. Since the hash function might cause collisions between (unrelated) features, a signed hash function is used and the sign of the hash value determines the sign of the value stored in the output matrix for a feature. This way, collisions are likely to cancel out rather than accumulate error, and the expected mean of any output feature’s value is zero. This mechanism is enabled by default with alternate_sign=True and is particularly useful for small hash table sizes (n_features &lt; 10000). . We can convert above vector to TFIDF using TfidfTransformer. check the below code . #instanciate the class vec_idftrans = TfidfTransformer() #fit with the hash BOW sparse data vec_idftrans.fit(hash_vector) ##transforming the data vec_tfidf2 = vec_idftrans.transform(hash_vector) print(&quot;tfidf using hash BOW --&gt;&quot;,vec_tfidf2.toarray()) . tfidf using hash BOW --&gt; [[0. 0.36691832 0.85483442 0.36691832 0. ] [0. 0.2419863 0.93961974 0.2419863 0. ] [0. 0. 1. 0. 0. ]] . This vectorizer is memory efficient but there are some cons for this as well, some of them are . There is no way to compute the inverse transform of the Hashing so there will be no interpretability of the model. | There can be collisions in the hashing. | . References: . https://scikit-learn.org/stable/ |",
            "url": "https://udibhaskar.github.io/practical-ml/nlp/feature%20extraction/bow/tfidf/hashing%20vectorizer/2020/03/13/Basic-feature-Extraction.html",
            "relUrl": "/nlp/feature%20extraction/bow/tfidf/hashing%20vectorizer/2020/03/13/Basic-feature-Extraction.html",
            "date": " • Mar 13, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Basics of Natural Language Processing",
            "content": "In any language, below are some language analysis categories. I will try to write basic processing using spaCy and NLTK. . . . Lexical Analysis . Lexical analysis is the task of segmenting text into its lexical expressions i.e. words/tokens. . . Tokenization . Converting sentence into tokens/words called as tokenization. There are many ways to do this. I will discuss some of them below. I am also creating 3 sentences as below . demo_sent1 = &quot;@uday can&#39;t wait for the #nlp notes YAAAAAAY!!! #deeplearning https://udibhaskar.github.io/practical-ml/&quot; demo_sent2 = &quot;That U.S.A. poster-print costs $12.40...&quot; demo_sent3 = &quot;I am writing NLP basics.&quot; all_sents = [demo_sent1, demo_sent2, demo_sent3] print(all_sents) . [&#34;@uday can&#39;t wait for the #nlp notes YAAAAAAY!!! #deeplearning https://udibhaskar.github.io/practical-ml/&#34;, &#39;That U.S.A. poster-print costs $12.40...&#39;, &#39;I am writing NLP basics.&#39;] . White Space Tokenizer . We can tokenize the data by splitting the data at space. check the code below . for sent in all_sents: print(sent.split(&#39; &#39;)) . [&#39;@uday&#39;, &#34;can&#39;t&#34;, &#39;wait&#39;, &#39;for&#39;, &#39;the&#39;, &#39;#nlp&#39;, &#39;notes&#39;, &#39;YAAAAAAY!!!&#39;, &#39;#deeplearning&#39;, &#39;https://udibhaskar.github.io/practical-ml/&#39;] [&#39;That&#39;, &#39;U.S.A.&#39;, &#39;poster-print&#39;, &#39;costs&#39;, &#39;$12.40...&#39;] [&#39;I&#39;, &#39;am&#39;, &#39;writing&#39;, &#39;NLP&#39;, &#39;basics.&#39;] . For some of the words, it is working perfectly like U.S.A., poster-printer but we are getting @uday, basics., $12.40..., #nlp as words but we have to remove those #,@,. etc... So this tokenizer may give bad results if we have words like this. . NLTK Word Tokenizer . It follows the conventions of the Penn Treebank. . from nltk.tokenize import word_tokenize for sent in all_sents: print(word_tokenize(sent)) . [&#39;@&#39;, &#39;uday&#39;, &#39;ca&#39;, &#34;n&#39;t&#34;, &#39;wait&#39;, &#39;for&#39;, &#39;the&#39;, &#39;#&#39;, &#39;nlp&#39;, &#39;notes&#39;, &#39;YAAAAAAY&#39;, &#39;!&#39;, &#39;!&#39;, &#39;!&#39;, &#39;#&#39;, &#39;deeplearning&#39;, &#39;https&#39;, &#39;:&#39;, &#39;//udibhaskar.github.io/practical-ml/&#39;] [&#39;That&#39;, &#39;U.S.A.&#39;, &#39;poster-print&#39;, &#39;costs&#39;, &#39;$&#39;, &#39;12.40&#39;, &#39;...&#39;] [&#39;I&#39;, &#39;am&#39;, &#39;writing&#39;, &#39;NLP&#39;, &#39;basics&#39;, &#39;.&#39;] . It is giving better results compared to the white space tokenizer but some words like can&#39;t and web addresses are not working fine. . NLTK Regex Tokenizer . We can write our own regex to split the sentence into tokens/words. . pattern = r&#39;&#39;&#39;(?x) # set flag to allow verbose regexps ... (?:[A-Z] .)+ # abbreviations, ... | w+(?:- w+)* # words with optional internal hyphens ... | $? d+(?: . d+)?%? # currency and percentages, ... | . . . # ellipsis ... | [][.,;&quot;&#39;?():-_`] # these are separate tokens; includes ], [ &#39;&#39;&#39; for sent in all_sents: print(nltk.regexp_tokenize(sent, pattern)) . [&#39;@&#39;, &#39;uday&#39;, &#39;can&#39;, &#34;&#39;&#34;, &#39;t&#39;, &#39;wait&#39;, &#39;for&#39;, &#39;the&#39;, &#39;nlp&#39;, &#39;notes&#39;, &#39;YAAAAAAY&#39;, &#39;deeplearning&#39;, &#39;https&#39;, &#39;:&#39;, &#39;udibhaskar&#39;, &#39;.&#39;, &#39;github&#39;, &#39;.&#39;, &#39;io&#39;, &#39;practical-ml&#39;] [&#39;That&#39;, &#39;U.S.A.&#39;, &#39;poster-print&#39;, &#39;costs&#39;, &#39;$12.40&#39;, &#39;...&#39;] [&#39;I&#39;, &#39;am&#39;, &#39;writing&#39;, &#39;NLP&#39;, &#39;basics&#39;, &#39;.&#39;] . . Note: There are many more NLTK tokenizers. You can refer to all of them in this link. . spaCy Tokenizer . Works on predefined regular expression rules for prefix_search, suffix_search, infix_finditer, token_match, and also Dependency Parsing to find sentence boundaries. . import spacy . ##loading spaCy english module nlp = spacy.load(&quot;en_core_web_sm&quot;) #printing for sent in all_sents: print([token.text for token in nlp(sent)]) . [&#39;@uday&#39;, &#39;ca&#39;, &#34;n&#39;t&#34;, &#39;wait&#39;, &#39;for&#39;, &#39;the&#39;, &#39;#&#39;, &#39;nlp&#39;, &#39;notes&#39;, &#39;YAAAAAAY&#39;, &#39;!&#39;, &#39;!&#39;, &#39;!&#39;, &#39;#&#39;, &#39;deeplearning&#39;, &#39;https://udibhaskar.github.io/practical-ml/&#39;] [&#39;That&#39;, &#39;U.S.A.&#39;, &#39;poster&#39;, &#39;-&#39;, &#39;print&#39;, &#39;costs&#39;, &#39;$&#39;, &#39;12.40&#39;, &#39;...&#39;] [&#39;I&#39;, &#39;am&#39;, &#39;writing&#39;, &#39;NLP&#39;, &#39;basics&#39;, &#39;.&#39;] . There are some tokenizers like SentencePiece that can learn how to tokenize form corpus of the data. I will discuss this in another blog. . . Warning: Our analysis and model performance also depends on the Tokenization algorithm so be careful while choosing the tokenization algorithm. If possible try with two or more algorithms or try to write custom rules based on your dataset/task. . Morphological Analysis . In linguistics, morphology is the study of the internal structure of words. I will try to explain some of them below. . Lemmatization . Using morphological analysis to return the dictionary form of a word i.e. the entry in a dictionary you would find all forms under. In Lemmatization root word is called Lemma. . from nltk.stem import WordNetLemmatizer lemmatizer = WordNetLemmatizer() print(lemmatizer.lemmatize(&#39;running&#39;)) print(lemmatizer.lemmatize(&#39;runner&#39;)) print(lemmatizer.lemmatize(&#39;runners&#39;)) . running runner runner . Stemming . Stemming is the process of producing morphological variants of a root/base word. . from nltk.stem import PorterStemmer stemmer = PorterStemmer() print(stemmer.stem(&#39;running&#39;)) print(stemmer.stem(&#39;runner&#39;)) print(stemmer.stem(&#39;runners&#39;)) . run runner runner . I will try to explain some other pre-processing techniques like POS tagging, Dependency Parsing while doing deep learning. . Stop Words . stop words usually refers to the most common words in a language, there is no single universal list of stop words used by all natural language processing tools, and indeed not all tools even use such a list. We can remove the stop words if you don&#39;t need exact meaning of a sentence. For text classification, we don&#39;t need those most of the time but, we need those for question and answer systems. word not is also a stop word in NLTK and this may be useful while classifying positive/negative sentence so be careful while removing the stopwords. You can get the stop words from NLTK as below. . from nltk.corpus import stopwords stopwords.words(&#39;english&#39;) . NLP pipeline . Text Preprocessing . You may get data from PDF files, speech, OCR, Docs, Web so you have to preprocess the data to get the better raw text. I would recommend you to read this blog. . . . Once you are done with basic cleaning, I would suggest do everything with spaCy. It is very easy to write the total pipeline. I took the IMDB dataset and written a pipeline to clean the data and get the tokens/words from the data. Before going to that, please check the below notebook that explains spaCy. . . I have written a class TextPreprocess which takes a raw text and gives tokens which will be given to the ML/DL algorithm. It will be very useful while deploying the algorithm in production if we write a clear pipeline like below. Writing this may take several days of analysis on the real-life text data. Once you have done with total analysis, please try to write a structured function/class which takes raw data and gives data that will be fed to the algorithm or another preprocessing pipeline. . ## Check below link to know more about pipeline class TextPreprocess(): def __init__(self): ##loading nlp object of spacy self.nlp = spacy.load(&quot;en_core_web_lg&quot;, disable=[&quot;tagger&quot;, &quot;parser&quot;]) # adding it to nlp object self.merge_entities_ = self.nlp.create_pipe(&quot;merge_entities&quot;) self.nlp.add_pipe(self.merge_entities_) ##removing not, neitherm never from stopwords, ##you can check all the spaCy stopwords from https://github.com/explosion/spaCy/blob/master/spacy/lang/en/stop_words.py self.nlp.vocab[&quot;not&quot;].is_stop = False self.nlp.vocab[&#39;neither&#39;].is_stop = False self.nlp.vocab[&#39;never&#39;].is_stop = False def clean_raw_text(self, text, remove_html=True, clean_dots=True, clean_quotes=True, clean_whitespace=True, convert_lowercase=True): &quot;&quot;&quot; Clean the text data. text: input raw text data remove_html: if True, it removes the HTML tags and gives the only text data. clean_dots: cleans all type of dots to fixed one clean_quotes: changes all type of quotes to fixed type like &quot; clean_whitespaces: removes 2 or more white spaces convert_lowercase: converts text to lower case &quot;&quot;&quot; if remove_html: # remove HTML ##separator=&#39; &#39; to replace tags with space. othewise, we are getting some unwanted type like ## &quot;make these characters come alive.&lt;br /&gt;&lt;br /&gt;We wish&quot; --&gt; make these characters come alive.We wish (no space between sentences) text = BeautifulSoup(text, &#39;html.parser&#39;).get_text(separator=&#39; &#39;) # https://github.com/blendle/research-summarization/blob/master/enrichers/cleaner.py#L29 if clean_dots: text = re.sub(r&#39;…&#39;, &#39;...&#39;, text) if clean_quotes: text = re.sub(r&#39;[`‘’‛⸂⸃⸌⸍⸜⸝]&#39;, &quot;&#39;&quot;, text) text = re.sub(r&#39;[„“]|( &#39; &#39;)|(,,)&#39;, &#39;&quot;&#39;, text) text = re.sub(r&#39;[-_]&#39;, &quot; &quot;, text) if clean_whitespace: text = re.sub(r&#39; s+&#39;, &#39; &#39;, text).strip() if convert_lowercase: text = text.lower() return text def get_token_list(self, text, get_spacy_tokens=False): &#39;&#39;&#39; gives the list of spacy tokens/word strings text: cleaned text get_spacy_tokens: if true, it returns the list of spacy token objects else, returns tokens in string format &#39;&#39;&#39; ##nlp object doc = self.nlp(text) out_tokens = [] for token in doc: if token.ent_type_ == &quot;&quot;: if not(token.is_punct or token.is_stop): if get_spacy_tokens: out_tokens.append(token) else: out_tokens.append(token.norm_) return out_tokens def get_preprocessed_tokens(self, text, remove_html=True, clean_dots=True, clean_quotes=True, clean_whitespace=True, convert_lowercase=True, get_tokens=True, get_spacy_tokens=False, get_string=False): &quot;&quot;&quot; returns the cleaned text text: input raw text data remove_html: if True, it removes the HTML tags and gives the only text data. clean_dots: cleans all type of dots to fixed one clean_quotes: changes all type of quotes to fixed type like &quot; clean_whitespaces: removes 2 or more white spaces convert_lowercase: converts text to lower case get_tokens: if true, returns output after tokenization else after cleaning only. get_spacy_tokens: if true, it returns the list of spacy token objects else, returns tokens in string format get_string: returns string output(combining all tokens by space separation) only if get_spacy_tokens=False &quot;&quot;&quot; text = self.clean_raw_text(text, remove_html, clean_dots, clean_quotes, clean_whitespace, convert_lowercase) if get_tokens: text = self.get_token_list(text, get_spacy_tokens) if (get_string and (not get_spacy_tokens)): text = &quot; &quot;.join(text) return text .",
            "url": "https://udibhaskar.github.io/practical-ml/nlp/basics/pipeline/text%20cleaning/tokenization/2020/03/10/Basics-of-language-processing.html",
            "relUrl": "/nlp/basics/pipeline/text%20cleaning/tokenization/2020/03/10/Basics-of-language-processing.html",
            "date": " • Mar 10, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Effective Training and Debugging of a Neural Networks",
            "content": "In this blog, I want to discuss Training and Debugging of a NN in a practical manner. . I am taking a cyber troll dataset. It is a classification data with labels aggressive or not. This is mostly inspired from this blog. . Whenever I train any neural network, I will divide that into subtasks as below. I am assuming, you already set your project goals and evaluation metrics. . If you don&#39;t have proper data, create/collect proper data. | Data preprocessing, EDA and creating structured data. | Writing a basic Model. | Training and debugging with very small data. Try to overfit to the very small training data(we will get to know basic errors and rectify it). | Writing a better data pipeline to train the NN with total data. | Train the model with Total data and Tune the model parameters. (While training, we may face some issues and you have to rectify those) | Compare the model with the SOTA/any other real-time systems and try to improve the model by changing the basic model or training a new model. so you have to go to step-3 again with a new model. | Compare the results and do the error analysis. I personally feel, based on error analysis, we can improve the model so much. It is similar to the active learning concept. | If you feel data is the issue, go to step-1 and check again. | ##basic imports import numpy as np import pandas as pd import random as rn import tensorflow as tf from tensorflow.keras.layers import LSTM, GRU, Dense, Input, Embedding from tensorflow.keras.models import Model . Data Processing . ##reading the data cyber_troll_data = pd.read_json(&#39;Dataset for Detection of Cyber-Trolls.json&#39;, lines=True) cyber_troll_data.head(2) . content annotation extras metadata . 0 Get fucking real dude. | {&#39;notes&#39;: &#39;&#39;, &#39;label&#39;: [&#39;1&#39;]} | NaN | {&#39;first_done_at&#39;: 1527503426000, &#39;last_updated... | . 1 She is as dirty as they come and that crook R... | {&#39;notes&#39;: &#39;&#39;, &#39;label&#39;: [&#39;1&#39;]} | NaN | {&#39;first_done_at&#39;: 1527503426000, &#39;last_updated... | . #basic preprocessing cyber_troll_data[&#39;label&#39;]=cyber_troll_data.annotation.apply(lambda x: int(x[&#39;label&#39;][0])) cyber_troll_data = cyber_troll_data[[&#39;content&#39;, &#39;label&#39;]] cyber_troll_data.head() . content label . 0 Get fucking real dude. | 1 | . 1 She is as dirty as they come and that crook R... | 1 | . 2 why did you fuck it up. I could do it all day ... | 1 | . 3 Dude they dont finish enclosing the fucking sh... | 1 | . 4 WTF are you talking about Men? No men thats no... | 1 | . #its a imbalance one cyber_troll_data.label.value_counts() . 0 12179 1 7822 Name: label, dtype: int64 . ##splitting data into train, validation and Test data. from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(cyber_troll_data.content, cyber_troll_data.label, test_size=0.40, stratify=cyber_troll_data.label, random_state=54) X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.50, stratify=y_test, random_state=32) tokenizer = tf.keras.preprocessing.text.Tokenizer() tokenizer.fit_on_texts(X_train) X_train_tokens = tokenizer.texts_to_sequences(X_train) X_test_tokens = tokenizer.texts_to_sequences(X_test) X_val_tokens = tokenizer.texts_to_sequences(X_val) number_vocab = len(tokenizer.word_index)+1 X_train_pad_tokens = tf.keras.preprocessing.sequence.pad_sequences(X_train_tokens, maxlen=24, padding=&#39;post&#39;, truncating=&#39;post&#39;) X_test_pad_tokens = tf.keras.preprocessing.sequence.pad_sequences(X_test_tokens, maxlen=24, padding=&#39;post&#39;, truncating=&#39;post&#39;) X_val_pad_tokens = tf.keras.preprocessing.sequence.pad_sequences(X_val_tokens, maxlen=24, padding=&#39;post&#39;, truncating=&#39;post&#39;) . We prepared the data. I am not doing perfect preprocessing and tokenization. You can do preprocessing in a better way. . We have, X_train_pad_tokens, y_train --&gt; To train X_val_pad_tokens, y_val --&gt; To validate and Tune X_test_pad_tokens, y_test --&gt; Don&#39;t use this data while trainig. Only use this after you are done with all the modelling. . I am creating Training and Validation datasets to iterate over those using the tf.data pipeline. Please use less data as of now because, it will be easier to debug and easier to know about the error if we have any in our network, I will discuss this below. I am only using the first 100 data points with a batch size of 32. . ##Creating the dataset( only 100 data points and will explain why after trainig process.) train_dataset = tf.data.Dataset.from_tensor_slices((X_train_pad_tokens[0:100], y_train[0:100])) train_dataset = train_dataset.shuffle(1000).batch(32, drop_remainder=True) train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE) ##creating test dataset using tf.data val_dataset = tf.data.Dataset.from_tensor_slices((X_val_pad_tokens[0:100], y_val[0:100])) val_dataset = val_dataset.batch(32, drop_remainder=True) val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE) . . Checking the data pairing issue and check the data given to neural network is correct or not. If it got corrupted, check/debug the data pipleline and rectify it. If you have images, try to plot the images and check. . below, i have written a basic for loop to print. You can also print the words corresponding to the numbers and check. . for input_text, output_label in train_dataset: print(input_text[0:3], output_label[0:3]) break . tf.Tensor( [[ 186 89 741 5 385 43 11 127 919 1082 157 1 9 251 5 628 3 6970 5 11 4641 30 6 40] [ 27 3 26 28 1021 29 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [4647 72 606 43 16 684 223 1 9 3 4648 923 0 0 0 0 0 0 0 0 0 0 0 0]], shape=(3, 24), dtype=int32) tf.Tensor([0 1 1], shape=(3,), dtype=int32) . Creating a Neural Network . Some of the rules to follow while writing/training your Neural Network. . Start with a simple architecture - We are doing a text classification so, we can try a single layer LSTM. | Use well studied default parameters like activation = relu, optimizer = adam, initialization = he for relu and Glorot for sigmoid/tanh. To know more about this, please read this blog. | Fix the random seeds so that we can reproduce the initializations/results to tune our models. - You have to fix all the random seeds in your model. | Normalize the input data. | . I am writing a simple LSTM model by following all the above rules. . ##LSTM ##fixing numpy RS np.random.seed(42) ##fixing tensorflow RS tf.random.set_seed(32) ##python RS rn.seed(12) ##model def get_model(): input_layer = Input(shape=(24,), name=&quot;input_layer&quot;) ##i am initilizing randomly. But you can use predefined embeddings. x_embedd = Embedding(input_dim=number_vocab, output_dim=100, input_length=24, mask_zero=True, embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=1, seed=23), name=&quot;Embedding_layer&quot;)(input_layer) x_lstm = LSTM(units=20, activation=&#39;tanh&#39;, recurrent_activation=&#39;sigmoid&#39;, use_bias=True, kernel_initializer=tf.keras.initializers.glorot_uniform(seed=26), recurrent_initializer=tf.keras.initializers.orthogonal(seed=54), bias_initializer=tf.keras.initializers.zeros(), name=&quot;LSTM_layer&quot;)(x_embedd) x_out = Dense(1, activation=&#39;sigmoid&#39;, kernel_initializer=tf.keras.initializers.glorot_uniform(seed=45), name=&quot;output_layer&quot;)(x_lstm) basic_lstm_model = Model(inputs=input_layer, outputs=x_out, name=&quot;basic_lstm_model&quot;) return basic_lstm_model basic_lstm_model = get_model() basic_lstm_model_anothertest = get_model() . Now i created two models named basic_lstm_model, basic_lstm_model_anothertest. Those two model initial weights will be the same because of the fixed random seed. This removes a factor of a variation and very useful to tune parameters by doing some experimentation on the same weight initialization. . we can check this as below. . [np.all(basic_lstm_model.get_weights()[i]==basic_lstm_model_anothertest.get_weights()[i]) for i in range(len(basic_lstm_model.get_weights()))] . [True, True, True, True, True, True] . Training a NN . Loss functions - If we calculate the loss in the wrong manner, we will get the wrong gradients and it doesn&#39;t learn perfectly. . Some of the mistakes in Loss functions: . one of the main mistakes in the loss creation is giving wrong inputs to the loss function. If we are using the cross-entropy, you have to give one-hot vector as input otherwise, use sparse_categorical_crossentropy(no need to give the one-hot vectors). | If you are using a function that calculates the loss using unnormalized logits, don&#39;t give the probability output as input to the loss function. ( check logits parameter in the tensorflow loss functions) | It is useful to mask unnecessary output while calculating loss. Eg: don&#39;t include output at the padded word position while calculation loss. | Selecting a loss function that allowing the calculation of large error values. Because of this, your loss may explode, you may get NaN and it affects the gradients too. | . ##masked loss Eg for sequence output. def maskedLoss(y_true, y_pred): #getting mask value mask = tf.math.logical_not(tf.math.equal(y_true, 0)) #calculating the loss loss_ = loss_function(y_true, y_pred) #converting mask dtype to loss_ dtype mask = tf.cast(mask, dtype=loss_.dtype) #applying the mask to loss loss_ = loss_*mask #getting mean over all the values loss_ = tf.reduce_mean(loss_) return loss_ . ##creating a loss object for this classification problem loss_function = tf.keras.losses.BinaryCrossentropy(from_logits=False, reduction=&#39;auto&#39;) . Training and validation functions . We have to take care of the toggling training flag because some of the layers behaves differently in training and testing. | . #optimizer optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) #trainign function @tf.function def train_step(input_vector, output_vector,loss_fn): #taping the gradients with tf.GradientTape() as tape: #for ward prop output_predicted = basic_lstm_model(inputs=input_vector, training=True) #loss calculation loss = loss_fn(output_vector, output_predicted) #getting gradients gradients = tape.gradient(loss, basic_lstm_model.trainable_variables) #applying gradients optimizer.apply_gradients(zip(gradients, basic_lstm_model.trainable_variables)) return loss, output_predicted #validation function @tf.function def val_step(input_vector, output_vector, loss_fn): #forward prop output_predicted = basic_lstm_model(inputs=input_vector, training=False) #loss calculation loss = loss_fn(output_vector, output_predicted) return loss, output_predicted . Training the NN with proper data. . While Training the model, I suggest you don&#39;t write the complex pipelining of the data and train your network at the start. If you do this, finding the bugs in your network is very difficult. Just get a few instances of data( maybe 10% of your total train data if you have 10K records) into your RAM and try to train your network. In this case, I have total data in my RAM so, I will slice a few batches and try to train the network. | . I will suggest you don&#39;t include the data augmentation as of now. It is useful for regularizing the model but try to avoid it at the start. Even if you do data augmentation, be careful about the labels. Eg: In the segmentation task, if you flip the image, you have to flip the label image as well. | . Check for casting issues. Eg. If layer needs int8, give the int8 value only as input. If you have float values, just cast the dtype. If data stored in the disk is float32, load the data into RAM with the same dtype. | . Check the data pairing issue i.e. while giving the train data, you have to give the correct pairs of x and y. Training the NN with proper data. | . Training the NN with data for 2 epochs and printing batchwise loss and finally getting mean of all those. Even if you use the .fit method of Keras API, it prints the aggregated value of loss/metric as part of verbose. You can check that aggregate class here . ##training EPOCHS=2 ##metrics # Even if you use .fit method, it alsocalculates batchwise loss/metric and aggregates those. train_loss = tf.keras.metrics.Mean(name=&#39;train_loss&#39;) val_loss = tf.keras.metrics.Mean(name=&#39;test_loss&#39;) for epoch in range(EPOCHS): #losses train_loss.reset_states() val_loss.reset_states() #training print(&#39;Batchwise Train loss&#39;) for text_seq, label_seq in train_dataset: loss_, pred_out = train_step(text_seq, label_seq, loss_function) print(loss_) train_loss(loss_) #validation print(&#39;Batchwise Val loss&#39;) for text_seq_val, label_seq_val in val_dataset: loss_test, pred_out_test = val_step(text_seq_val, label_seq_val, loss_function) print(loss_test) val_loss(loss_test) template = &#39;Epoch {}, Mean Loss: {}, Mean Val Loss: {}&#39; print(template.format(epoch+1, train_loss.result(), val_loss.result())) print(&#39;-&#39;*50) . Batchwise Train loss tf.Tensor(0.69066906, shape=(), dtype=float32) tf.Tensor(0.6978342, shape=(), dtype=float32) tf.Tensor(0.7214557, shape=(), dtype=float32) Batchwise Val loss tf.Tensor(0.7479876, shape=(), dtype=float32) tf.Tensor(0.6868224, shape=(), dtype=float32) tf.Tensor(0.71952724, shape=(), dtype=float32) Epoch 1, Mean Loss: 0.7033197283744812, Mean Val Loss: 0.7181124687194824 -- Batchwise Train loss tf.Tensor(0.6816538, shape=(), dtype=float32) tf.Tensor(0.69258916, shape=(), dtype=float32) tf.Tensor(0.6689039, shape=(), dtype=float32) Batchwise Val loss tf.Tensor(0.744266, shape=(), dtype=float32) tf.Tensor(0.681653, shape=(), dtype=float32) tf.Tensor(0.71762204, shape=(), dtype=float32) Epoch 2, Mean Loss: 0.6810489296913147, Mean Val Loss: 0.7145137190818787 -- . Debugging and Enhancing NN . Till now, we have created a basic NN for our problem and trained the NN. Now I will discuss some hacks to debug and enhance your training process to get better results. . Using Basic print statements and checking the shapes of input and output of every layer. Using this, we can remove the shape related error or basic errors related to output while creating a model. If you want to print in tensorflow code, please use tf.print | . With Eager execution, we can debug our code very easily. it can be done using pdb or using any ide. You have to set tf.config.experimental_run_functions_eagerly(True) to debug your tf2.0 functions. | . ##LSTM tf.config.experimental_run_functions_eagerly(True) ##fixing numpy RS np.random.seed(42) ##fixing tensorflow RS tf.random.set_seed(32) ##python RS rn.seed(12) import pdb ##model def get_model_debug(): input_layer_d = Input(shape=(24,), name=&quot;input_layer&quot;) ##i am initilizing randomly. But you can use predefined embeddings. x_embedd_d= Embedding(input_dim=number_vocab, output_dim=100, input_length=24, mask_zero=True, embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=1, seed=23), name=&quot;Embedding_layer&quot;)(input_layer_d) #LSTM x_lstm_d = LSTM(units=20, activation=&#39;tanh&#39;, recurrent_activation=&#39;sigmoid&#39;, use_bias=True, kernel_initializer=tf.keras.initializers.glorot_uniform(seed=26), recurrent_initializer=tf.keras.initializers.orthogonal(seed=54), bias_initializer=tf.keras.initializers.zeros(), name=&quot;LSTM_layer&quot;)(x_embedd_d) #trace pdb.set_trace() x_out_d = Dense(1, activation=&#39;sigmoid&#39;, kernel_initializer=tf.keras.initializers.glorot_uniform(seed=45), name=&quot;output_layer&quot;)(x_lstm_d) basic_lstm_model_d = Model(inputs=input_layer_d, outputs=x_out_d, name=&quot;basic_lstm_model_d&quot;) return basic_lstm_model_d basic_model_debug = get_model_debug() tf.config.experimental_run_functions_eagerly(False) . &gt; &lt;ipython-input-14-476c66b41633&gt;(31)get_model_debug() -&gt; x_out_d = Dense(1, activation=&#39;sigmoid&#39;, kernel_initializer=tf.keras.initializers.glorot_uniform(seed=45), . {&#39;input_layer_d&#39;: &lt;tf.Tensor &#39;input_layer_2:0&#39; shape=(None, 24) dtype=float32&gt;, &#39;x_embedd_d&#39;: &lt;tf.Tensor &#39;Embedding_layer_2/Identity:0&#39; shape=(None, 24, 100) dtype=float32&gt;, &#39;x_lstm_d&#39;: &lt;tf.Tensor &#39;LSTM_layer_2/Identity:0&#39; shape=(None, 20) dtype=float32&gt;} . &gt; &lt;ipython-input-14-476c66b41633&gt;(32)get_model_debug() -&gt; name=&#34;output_layer&#34;)(x_lstm_d) . &gt; &lt;ipython-input-14-476c66b41633&gt;(34)get_model_debug() -&gt; basic_lstm_model_d = Model(inputs=input_layer_d, outputs=x_out_d, name=&#34;basic_lstm_model_d&#34;) . You can also Debug the Trainig loopas shown below. For PDB instrctions, please check this PDF. . My preference and suggestion is to use IDE Debugger . ##training EPOCHS=1 ##metrics # Even if you use .fit method, it alsocalculates batchwise loss/metric and aggregates those. train_loss = tf.keras.metrics.Mean(name=&#39;train_loss&#39;) tf.config.experimental_run_functions_eagerly(True) for epoch in range(EPOCHS): train_loss.reset_states() print(&#39;Batchwise Train loss&#39;) for text_seq, label_seq in train_dataset: pdb.set_trace() loss_, pred_out = train_step(text_seq, label_seq, loss_function) print(loss_) train_loss(loss_) template = &#39;Epoch {}, Mean Loss: {}&#39; print(template.format(epoch+1, train_loss.result())) print(&#39;-&#39;*50) tf.config.experimental_run_functions_eagerly(False) . Batchwise Train loss &gt; &lt;ipython-input-15-aa3750dbfb83&gt;(13)&lt;module&gt;() -&gt; loss_, pred_out = train_step(text_seq, label_seq, loss_function) . --Call-- &gt; d: softwares anaconda3 envs tf2 lib site-packages tensorflow_core python eager def_function.py(551)__call__() -&gt; def __call__(self, *args, **kwds): . tf.Tensor(0.66431165, shape=(), dtype=float32) &gt; &lt;ipython-input-15-aa3750dbfb83&gt;(12)&lt;module&gt;() -&gt; pdb.set_trace() . tf.Tensor(0.6668887, shape=(), dtype=float32) &gt; &lt;ipython-input-15-aa3750dbfb83&gt;(13)&lt;module&gt;() -&gt; loss_, pred_out = train_step(text_seq, label_seq, loss_function) . tf.Tensor(0.6523603, shape=(), dtype=float32) Epoch 1, Mean Loss: 0.6611868739128113 -- . Once you are done with the creation of the model, Try to Train the model with less data( i have taken 100 samples) and try to overfit the model to that data. To do so we increase the capacity of our model (e.g. add layers or filters) and verify that we can reach the lowest achievable loss (e.g. zero). If your model is unable to overfit a few data points, then either it&#39;s too small (which is unlikely in today&#39;s age), or something is wrong in its structure or the learning algorithm. check for bugs and try to remove those. I will discuss some of the bugs below. If this model is working fine without any bugs, you can train with full data. | . Tensorboard is another important tool to debug NN while training. You can visualize the Loss, metrics, gradient/output histograms, distributions, graph and many more. I am writing code to plot all these in the tensorboard. . | As of now, we are printing/plotting the Mean loss/metric for all the batches in one epoch and, based on this we are analyzing the model performance. This may lead to wrong models for some of the loss functions/metrics. Even if you use the smoothing, it is not an accurate one, it will get an exponentially weighted average over batch-wise loss/metric. so Try to get a loss/metric for entire data of train and Val/test. If you have time/space constraint, at least get for the val/test data. Eg: Mean of Cross entropy over batches is equal to the cross-entropy over total data but not for AUC/F1 score. . Below I have written code that calculates loss and metric(AUC) over batches and gets the mean as well as a total loss at once and a better Training and validation functions with tensorboard. please look into it. . | . ##training ##model creation basic_lstm_model = get_model() ##optimizer optimizer = tf.keras.optimizers.Adam(learning_rate=0.005) ##metric from sklearn.metrics import roc_auc_score ##train step function to train @tf.function def train_step(input_vector, output_vector,loss_fn): with tf.GradientTape() as tape: #forward propagation output_predicted = basic_lstm_model(inputs=input_vector, training=True) #loss loss = loss_fn(output_vector, output_predicted) #getting gradients gradients = tape.gradient(loss, basic_lstm_model.trainable_variables) #applying gradients optimizer.apply_gradients(zip(gradients, basic_lstm_model.trainable_variables)) return loss, output_predicted, gradients ##validation step function @tf.function def val_step(input_vector, output_vector, loss_fn): #getting output of validation data output_predicted = basic_lstm_model(inputs=input_vector, training=False) #loss calculation loss = loss_fn(output_vector, output_predicted) return loss, output_predicted import math #batch size BATCH_SIZE=32 ##number of epochs EPOCHS=10 ##metrics # Even if you use .fit method, it alsocalculates batchwise loss/metric and aggregates those. train_loss = tf.keras.metrics.Mean(name=&#39;train_loss&#39;) val_loss = tf.keras.metrics.Mean(name=&#39;val_loss&#39;) train_metric = tf.keras.metrics.Mean(name=&quot;train_auc&quot;) val_metric = tf.keras.metrics.Mean(name=&quot;val_metric&quot;) #tensorboard file writers wtrain = tf.summary.create_file_writer(logdir=&#39;logs train&#39;) wval = tf.summary.create_file_writer(logdir=&#39;logs val&#39;) #no of data points/batch_size i.e number of iterations in the one epoch iters = math.ceil(100/BATCH_SIZE) #training anf validating for epoch in range(EPOCHS): #resetting the states of the loss and metrics train_loss.reset_states() val_loss.reset_states() train_metric.reset_states() val_metric.reset_states() ##counter for train loop iteration counter = 0 #lists to save true and validation data. train_true = [] train_predicted = [] val_true = [] val_predicted = [] #ietrating over train data batch by batch for text_seq, label_seq in train_dataset: #train step loss_, pred_out, gradients = train_step(text_seq, label_seq, loss_function) #adding loss to train loss train_loss(loss_) #counting the step number temp_step = epoch*iters+counter counter = counter + 1 #calculating AUC for batch batch_metric = roc_auc_score(label_seq, pred_out) train_metric(batch_metric) #appending it to list train_predicted.append(pred_out) train_true.append(label_seq) ##tensorboard with tf.name_scope(&#39;per_step_training&#39;): with wtrain.as_default(): tf.summary.scalar(&quot;batch_loss&quot;, loss_, step=temp_step) tf.summary.scalar(&#39;batch_metric&#39;, batch_metric, step=temp_step) with tf.name_scope(&quot;per_batch_gradients&quot;): with wtrain.as_default(): for i in range(len(basic_lstm_model.trainable_variables)): name_temp = basic_lstm_model.trainable_variables[i].name tf.summary.histogram(name_temp, gradients[i], step=temp_step) #calculating the final loss and metric train_true = tf.concat(train_true, axis=0) train_predicted = tf.concat(train_predicted, axis=0) train_loss_final = loss_function(train_true, train_predicted) train_metric_auc = roc_auc_score(train_true, train_predicted) #validation data for text_seq_val, label_seq_val in val_dataset: #getting val output loss_val, pred_out_val = val_step(text_seq_val, label_seq_val, loss_function) #appending to lists val_true.append(label_seq_val) val_predicted.append(pred_out_val) val_loss(loss_val) #calculating metric batch_metric_val = roc_auc_score(label_seq_val, pred_out_val) val_metric(batch_metric_val) #calculating final loss and metric val_true = tf.concat(val_true, axis=0) val_predicted = tf.concat(val_predicted, axis=0) val_loss_final = loss_function(val_true, val_predicted) val_metric_auc = roc_auc_score(val_true, val_predicted) #printing template = &#39;&#39;&#39;Epoch {}, Train Loss: {:0.6f}, Mean batch Train Loss: {:0.6f}, AUC: {:0.5f}, Mean batch Train AUC: {:0.5f}, Val Loss: {:0.6f}, Mean batch Val Loss: {:0.6f}, Val AUC: {:0.5f}, Mean batch Val AUC: {:0.5f}&#39;&#39;&#39; print(template.format(epoch+1, train_loss_final.numpy(), train_loss.result(), train_metric_auc, train_metric.result(), val_loss_final.numpy(), val_loss.result(), val_metric_auc, val_metric.result())) print(&#39;-&#39;*30) #tensorboard with tf.name_scope(&quot;per_epoch_loss_metric&quot;): with wtrain.as_default(): tf.summary.scalar(&quot;mean_loss&quot;, train_loss.result().numpy(), step=epoch) tf.summary.scalar(&#39;loss&#39;, train_loss_final.numpy(), step=epoch) tf.summary.scalar(&#39;metric&#39;, train_metric_auc, step=epoch) tf.summary.scalar(&#39;mean_metric&#39;, train_metric.result().numpy(), step=epoch) with wval.as_default(): tf.summary.scalar(&#39;mean_loss&#39;, val_loss.result().numpy(), step=epoch) tf.summary.scalar(&#39;loss&#39;, val_loss_final.numpy(), step=epoch) tf.summary.scalar(&#39;metric&#39;, val_metric_auc, step=epoch) tf.summary.scalar(&#39;mean_metric&#39;, val_metric.result().numpy(), step=epoch) . Epoch 1, Train Loss: 0.700775, Mean batch Train Loss: 0.700775, AUC: 0.46829, Mean batch Train AUC: 0.45378, Val Loss: 0.704532, Mean batch Val Loss: 0.704532, Val AUC: 0.48223, Mean batch Val AUC: 0.48844 Epoch 2, Train Loss: 0.596350, Mean batch Train Loss: 0.596350, AUC: 0.86608, Mean batch Train AUC: 0.86355, Val Loss: 0.691127, Mean batch Val Loss: 0.691127, Val AUC: 0.52128, Mean batch Val AUC: 0.53295 Epoch 3, Train Loss: 0.508518, Mean batch Train Loss: 0.508518, AUC: 0.98973, Mean batch Train AUC: 0.98923, Val Loss: 0.681388, Mean batch Val Loss: 0.681388, Val AUC: 0.55682, Mean batch Val AUC: 0.57112 Epoch 4, Train Loss: 0.441114, Mean batch Train Loss: 0.441114, AUC: 0.99554, Mean batch Train AUC: 0.99460, Val Loss: 0.673574, Mean batch Val Loss: 0.673574, Val AUC: 0.58578, Mean batch Val AUC: 0.60539 Epoch 5, Train Loss: 0.368985, Mean batch Train Loss: 0.368985, AUC: 0.99868, Mean batch Train AUC: 0.99861, Val Loss: 0.667929, Mean batch Val Loss: 0.667929, Val AUC: 0.61167, Mean batch Val AUC: 0.62760 Epoch 6, Train Loss: 0.306646, Mean batch Train Loss: 0.306646, AUC: 0.99956, Mean batch Train AUC: 1.00000, Val Loss: 0.664882, Mean batch Val Loss: 0.664882, Val AUC: 0.62835, Mean batch Val AUC: 0.63807 Epoch 7, Train Loss: 0.249700, Mean batch Train Loss: 0.249700, AUC: 1.00000, Mean batch Train AUC: 1.00000, Val Loss: 0.666024, Mean batch Val Loss: 0.666024, Val AUC: 0.63756, Mean batch Val AUC: 0.64217 Epoch 8, Train Loss: 0.195906, Mean batch Train Loss: 0.195906, AUC: 1.00000, Mean batch Train AUC: 1.00000, Val Loss: 0.671024, Mean batch Val Loss: 0.671024, Val AUC: 0.64063, Mean batch Val AUC: 0.64618 Epoch 9, Train Loss: 0.151549, Mean batch Train Loss: 0.151549, AUC: 1.00000, Mean batch Train AUC: 1.00000, Val Loss: 0.679804, Mean batch Val Loss: 0.679804, Val AUC: 0.64458, Mean batch Val AUC: 0.64464 Epoch 10, Train Loss: 0.111988, Mean batch Train Loss: 0.111988, AUC: 1.00000, Mean batch Train AUC: 1.00000, Val Loss: 0.695000, Mean batch Val Loss: 0.695000, Val AUC: 0.64283, Mean batch Val AUC: 0.64751 . I trained the model for 10 epochs and my loss is decreasing and AUC of train data became 1(overfit). But some times it may not overfit to the model. If it is not overfitting, there may be so many reasons like code written to create the model is incorrect, the model is not capable of learning the data, learning problems like vanishing or exploding gradients and many more. I will discuss these problems below and These problems may occur even while training with total data. . Check whether forward propagation is correct or not . while training NN, we will use the vectorizing implementations of data manipulation. If we did any mistake in these implementations, our training process will give bad results. We can verify this with a simple hack using back prop dependency. Below are the steps to do. . Take a few data points. Here I am taking 5 data points. You can get it from the data or you can generate random data with the same shape. | do forward propagation on the model we created with the above batch data. | write a loss function that takes the true values, predicted values and returns loss as sum of the i^th data point output where i less than 5. I am using 3. | do the back prop and check the gradients with respect to the input data points. If you are getting non zero gradients only for i-th data point, your forward propagation is right otherwise, there is some error in the forward propagation and you have to debug the code to check the error. | . In the implementation below, I have written basic implementation, not included any tensorboard/metrics and there is no need for those as well. . Note: Gradient won&#8217;t flow through the embedding layer so you will get None gradients if you calculate the gradient with of loss with respect to the input. If you have the embedding layer at starting, please remove the embedding layer and give the input directly to the next layer. It is very easy to do because This layer can only be used as the first layer in a model. . ##same model with name changes and without emedding layer. def get_model_check(): ##directly using embedding dimention of 1. It is only for checking so no problem with it. input_layer = Input(shape=(24, 1), batch_size=10, name=&quot;input_layer_debug&quot;) ##i am initilizing randomly. But you can use predefined embeddings. #x_embedd = Embedding(input_dim=13732, output_dim=100, input_length=24, mask_zero=True, #embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=1, seed=23), #name=&quot;Embedding_layer&quot;)(input_layer) x_lstm = LSTM(units=20, activation=&#39;tanh&#39;, recurrent_activation=&#39;sigmoid&#39;, use_bias=True, kernel_initializer=tf.keras.initializers.glorot_uniform(seed=26), recurrent_initializer=tf.keras.initializers.orthogonal(seed=54), bias_initializer=tf.keras.initializers.zeros(), name=&quot;LSTM_layer_debug&quot;)(input_layer) x_out = Dense(1, activation=&#39;sigmoid&#39;, kernel_initializer=tf.keras.initializers.glorot_uniform(seed=45), name=&quot;output_layer_debug&quot;)(x_lstm) basic_model_debug = Model(inputs=input_layer, outputs=x_out, name=&quot;basic_lstm_model_debug&quot;) return basic_model_debug basic_model_debug = get_model_check() ##generated random 5 data points of shape (24,1) i.e 4 time steps and 1 dim embedding. temp_features = np.random.randint(low=1, high=5, size=(5,24, 1)) ##generated the a random output zero or 1. I think, there is no use for this as well because #we will calculate loss only with predicted values temp_outs = np.random.randint(0, 2, size=(5,1)) def loss_to_ckgrads(y_true, y_pred): #y_pred is one dimentional you can give directly one data point prediction as loss. #I am giving loss as 3rd data point prediction so we will get non zero gradients only for 3rd data point. #if your prediction is sequence, please add all the i-th data point predictions and return those. return y_pred[2] def get_gradient(model, x_tensor): #taping the gradients with tf.GradientTape() as tape: #explicitly telling to watch for input vector. it won&#39;t watch with repect to any inputs by default. #it only watches the gradents with weight vectors tape.watch(x_tensor) #model predictions preds = model(x_tensor) #getting the loss loss = loss_to_ckgrads(temp_outs, preds) #getting the gradients grads = tape.gradient(loss, x_tensor) return grads ##making temp_feature as varible. We can get the gradients only if it is a varible so chnaging it to variable temp_features = tf.Variable(tf.convert_to_tensor(temp_features, dtype=tf.float32)) ## grads = get_gradient(basic_model_debug, temp_features) for i in grads: #checking whether all zeros or not #except 3rd all the grdients should be zero i.e True print(all(i==0)) . True True False True True . If you are not getting all true except the i-th one, you may have any issue in your code. You have to check that and resolve it. Without that, don&#39;t go to another step.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; What to do when Loss Explodes . while training NN, you may get NaN/inf loss becuase of large or small values. Below are some causes . Numerical stability issues. Check the multiplications, if you are multiplying so many tensors at once, apply log and make it to addition. | Check for the division operation. any zero division is happening or not. Try to add a small constant like 1e-12 to the denominator. | Check the softmax function. If your vocab size if very large, try not to use the softmax function. calculate the loss based on the logits. | . | If the updates to the weights are very large, you may get numerical instability and it may explode. Check for the Learning rate. If the learning rate is high, you may get this problem as well. | Check for the exploding gradient problem. In tensorboard, you can visualize the gradient histograms and you can check the problem. If gradients are exploding, try to clip the gradients. You can apply tf.linalg.normalize or tf.clip_by_value to your gradients after getting gradients from the GradientTape. | . | It may occur because of a poor choice of loss function i.e. allowing the calculation of large error values. | It may occur because of the poor data preparation i.e. allowing large differences in the target variables. | . What to do when loss Increases . while training NN, our loss may increase some times. Below are some causes . Check for the Learning rate. If the learning rate is high, you may get this problem as well. | Check for the wrong loss function. Especially sign of the loss function. | Activation functions applying over wrong dimensions. (you can find this out using the point number 1(checking forward propagation is correct or not) | . What to do when loss Oscillate . while training NN, our loss may oscillate. Below are some causes . Check for the Learning rate. If the learning rate is high, you may get this problem as well. | Sometimes it may occur because of the exploding gradient problem. so check for that one as well. You can check this using the Tensorboard. | It may occur due to data pairing issues/data corruption. We already discussed this. so make sure to get the proper data. | . What to do when loss is constant . while training NN, our loss constant. Below are some causes . If the updates to the weights are very low, you may end up in the same position. Check for the learning rate. If the learning rate is low, our weights won&#39;t update much so you may get this problem. | Check for Vanishing Gradient problem. In Tensorboard, you can visualize the gradient histograms and you can check the problem. You can solve this by changing the activations to relu/leaky relu. | You can add skip connections to an easier flow of gradients. | If you have long sequences in RNN, you can divide into smaller ones and train with stateful LSTM&#39;s(Truncated Back prop) | Better weight initialization may reduce this. | . | . | Too much regularization may also cause this. | If you are using Relu activation, it may occur due to the dead neurons. | Incorrect inputs to the loss function. I already discussed this while discussing the loss functions. | . What if we get memory Errors . while training NN, many people face the memory exhaust errors because of the computing constraints. . If you are getting GPU memory exhaust error, try to reduce the batch size and train the neural network. | If your data doesn&#39;t fit into the RAM you have, Try to create a data pipeline using tf.data or Keras/Python Data Generators and load the batchwise data. My personal choice is to use tf.data pipelines. Please check this blog to know more about it. | Please try to check for the duplicate operations like creating multiple models, storing temporary variables in the GPU memory. | . What if we Underfit to the data . some suggestions to make in decreasing order of priority . Make your model bigger | Reduce/Remove regularization(L1/L2/Dropout) if any. | Do error analysis. based on this try to change the preprocessing/data if needed. | Read technical papers and choose the state of the art models. | Tune hyperparameters | Add custom features if needed. | . What if we Overfit to the data . some suggestions to make in decreasing order of priority . Add more training data | Add normalization layers(BN, layer norm) | Add data augmentation | Increase regularization | Do error analysis. based on this try to change the preprocessing/data if needed. | Choose a different model | Tune hyperparameters | . You can check some of my other blogs at this link. This is my LinkedIn and GitHub&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; .",
            "url": "https://udibhaskar.github.io/practical-ml/debugging%20nn/neural%20network/overfit/underfit/2020/02/03/Effective_Training_and_Debugging_of_a_Neural_Networks.html",
            "relUrl": "/debugging%20nn/neural%20network/overfit/underfit/2020/02/03/Effective_Training_and_Debugging_of_a_Neural_Networks.html",
            "date": " • Feb 3, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I am a Machine Learning Engineer with four years of industry experience. Currently working on Query resolution systems and semantic similarity search with NLP. Involve in research and designing an approach, followed by code development. You can check my Linkedin and GitHub .",
          "url": "https://udibhaskar.github.io/practical-ml/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://udibhaskar.github.io/practical-ml/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}