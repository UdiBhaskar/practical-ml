{
  
    
        "post0": {
            "title": "Probability Distributions and use cases",
            "content": "Discrete distributions . import numpy as np import matplotlib.pyplot as plt import seaborn as sns from matplotlib import rcParams # figure size in inches rcParams[&#39;figure.figsize&#39;] = 11.7,8.27 . Bernoulli distribution . A Bernoulli random variable has exactly two possible outcomes. We typically label one of these outcomes a &quot;success&quot; and the other outcome a &quot;failure&quot;. We may also denote a success by 1 and a failure by 0. . The flip of a coin is modeled well by a Bernoulli distribution, as it is a single trial with a fixed nonzero probability of success (even if that probability is difficult to pin down if the coin is unfair). . Note: Probability of success = p, mean = p, Var = p(1-p) . We can silumate using np.random.random() . import numpy as np np.random.random(1) . Binomial Distribution . The binomial distribution describes a sequence of identical, independent Bernoulli trials. That is, each trial has the same probability of success, and the results of one trial do not affect any of the following trials. . let Probability of success = p . begin{align} text{Probability of k success in n trails} = P(k) &amp;= binom{n}{k} p^k (1-p)^{n-k} end{align} . Note: mean = np, Var = np(1-p) . . From above formual, we can tell given a 20 coin flips, what is the probability of getting 7 heads if getting a head is having probability of 0.35. n = 20 k = 7 p = 0.35 Then, P(7) = 0.18440118638 . We can simulate using np.random.binomial . n = 20 p = 0.35 size=1000 np.random.seed(4) vals = np.random.binomial(n, p, size) sns.distplot(vals, kde=False, rug=False, color=&#39;red&#39;, label=&quot;number of heads in simulation of 20 coin flips&quot;) plt.xlabel(&#39;No of Heads&#39;) plt.ylabel(&#39;No of times occur out of 1000 times&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x2da2f8bfa88&gt; . sns.distplot(vals, hist=False, kde=True, color=&#39;red&#39;, label=&quot;Probability of number of heads in simulation of 20 coin flips&quot;) plt.xlabel(&#39;No of Heads&#39;) plt.ylabel(&#39;Probability&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x2da301f0608&gt; . count_7 = sum(vals==7) print(&quot;count&quot;, count_7) prob = count_7/1000 print(&#39;probability&#39;, prob) . count 179 probability 0.179 . Theoritical probability we got from formula is 0.1844 and now we got 0.179. . From above simulation we can also tell for probability if every any number of heads. we got a curve which is similar to normal distribution. . . Warning: To check binomial distribution, It has to satisfy below conditions - The trials are independent. - The number of trials is fixed(n). - Each trial outcome is classified as a success or failure. - The probability of success(p) is the same for each trial. . Usecase-1 . Let&#39;s take you are working in a food delivery company. Based on previous deliveries, the probability of delivering the wrong item is 0.0085. Per day, company delivers average of 1500 items. Loss per one wrong delivery is 100rs. Calculate the maximum loss we may get? | based on above info n = 1500, p = 0.0085 . np.random.seed(5) wrong_deliveries = np.random.binomial(1500, 0.0085, 10000) . sns.distplot(wrong_deliveries, hist=False, kde=True, color=&#39;red&#39;, label=&quot;Wrong Deliveries&quot;) plt.hist(wrong_deliveries, density=True) plt.xlabel(&#39;No of deliveries&#39;) plt.ylabel(&#39;Probability&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x2da2fb3ef08&gt; . max(wrong_deliveries) . 30 . kwargs = {&#39;cumulative&#39;: True} sns.distplot(wrong_deliveries, hist_kws=kwargs, kde_kws=kwargs, label=&#39;CDF of # of wrong delivery&#39;, color=&#39;red&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x2da350e6d08&gt; . np.percentile(wrong_deliveries, 95) . 19.0 . Based on CDF or using np.percentile we can tell how many wrong orders with a probability and the we can calculate the loss. . Usecase-2 . Let&#39;s take you are working in a Manufacturing company. Based on previous data, 3% of items produced are defective. If we produce 5000 items a day, what is probabability to get a 4500 non defective items. or analyze the how many days it may needed to get 5 million non defective items? | Usecase-3 . Let&#39;s consider you are working in a tele-marketing company. Probability of converting a lead to sale is 6.5%, No of lead calls is 100 per day.. If you want to increase the revenue by some 10%, how many calls we have to make or how much conversion rate we need? How many employees we can recruit to increase the no of calls? | Poisson Distribution . The Poisson distribution is often useful for estimating the number of events in a large population over a unit of time. . Let&#39;s say, we have to calculate how many hits we will get to my website hourly. let&#39;s say probability of hit is 0.2 per hour. . We can model this even using the binomial RV if we have one hit or not in a hour but here we may get zero hits, 1 hit or some hour may give more than 1 hit. The problem with binomial is that it cannot contain more than 1 event in the unit of time (in this case, 1 hr is the unit time). The unit of time can only have 0 or 1 event. If we divid the unit of time into smaller parts, we can handle it i.e if we do n --&gt; infinite ( i.e. p --&gt; 0) in the Binomial distribution, we can model it. . The Poisson Distribution, doesn’t require you to know n or p. We are assuming n is infinitely large and p is infinitesimal. The only parameter of the Poisson distribution is the rate λ (the expected value of x). . begin{align} P(k) = frac{e^{- lambda} lambda^{k}} {k!} end{align} . Note: mean = Lambda, Var = Lambda . Usecase-1 . Let&#39;s take you are working in E-Learning company. Based on previous data, on average comapany getting 7 queries per hour. What is the probability that getting 12 queries or more in the next hour. | lamda = 7 np.random.seed(12) no_queries = np.random.poisson(lamda, size=20000) . sns.distplot(no_queries, hist=False, kde=True, color=&#39;red&#39;, label=&quot;no of queries&quot;) plt.hist(no_queries, density=True) plt.xlabel(&#39;No of queries&#39;) plt.ylabel(&#39;Probability&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x2da359304c8&gt; . print(&#39;probability&#39;, sum(no_queries&gt;=12)/len(no_queries)) . probability 0.0545 . Geometric Distribution . The geometric distribution represents the number of failures before the first success in a sequence of Bernoulli trials. . . let Probability of success = p . . begin{align} text{Probability of having exactly k failures before the first success} = P(k) = (1-p)^{k}p end{align} . . We can simulate it using np.random.geometric . Use Case-1 . A programmer has a 90% chance of finding a bug every time he compiles his code, and it takes him two hours to rewrite his code every time he discovers a bug. What is the probability that he will finish his program by the end of his workday? Assume that a workday is 8 hours and that the programmer compiles his code immediately at the beginning of the day. | Use Case-2 . 2.. In cost-benefit analyses, such as a company deciding whether to fund research trials that, if successful, will earn the company some estimated profit, the goal is to reach a success before the cost outweighs the potential gain. . Continuous distributions . Normal distribution . The normal distribution is described by two parameters μ and σ, representing the mean and standard deviation of the random variable X respectively. . . begin{align} text{Probability Density Fn} = f(x) &amp;= dfrac{1}{ sqrt{2 pi} sigma} e^{- dfrac{(x- mu)^2}{2 sigma^2}} end{align} . . We can simulate it using np.random.normal . normal_vals = np.random.normal(0, 5, 1000) . sns.distplot(normal_vals, hist=False, kde=True, color=&#39;red&#39;, label=&quot;Normal Dist&quot;) plt.hist(normal_vals, density=True) plt.legend() . &lt;matplotlib.legend.Legend at 0x2da35d863c8&gt; . . 68-95-99.7 rule . . Exponential distribution . To predict the amount of waiting time until the next event (i.e., success, failure, arrival, etc.). You can thik similar to poission distribution. In poission distribution, we can predict how many events occur in a unit of time. In Exponential distribution, amout of time needed to event occur. If the number of events per unit time follows a Poisson distribution, then the amount of time between events follows the exponential distribution. . . begin{align} text{Probability Density Fn} = f(x) &amp;= lambda e^{- lambda k} end{align} . . Warning: X ~ Exp(0.3) is to remember that 0.3 is not a time duration, but it is an event rate, which is the same as the parameter λ in a Poisson process. When rate changes, it won&#8217;t work. rate has to be constant . . We can simulate it using np.random.exponential . . Use case-1 . At a call center, calls come in every 20 minutes on average. What is the approximate probability that no calls will come in for a 30 minute period? | The time between calls can be represented by an exponential distribution with Lambda=3, since one call every 20 minutes is 3 calls per hour. we have to get the probability that at least half an hour passes between calls . np.random.seed(6) calls_time = np.random.exponential(1/3, 10000) . sum(vals&gt;0.5)/len(vals) . 0.2292 . sns.distplot(calls_time, hist=False, kde=True, color=&#39;red&#39;, label=&quot;Calls time&quot;) plt.hist(calls_time, density=True) plt.legend() . &lt;matplotlib.legend.Legend at 0x2da35d98648&gt; . Use case-2 . A computer repair customer service takes an average of 3 days repair. How long (approximately, in days) should customer has to wait to pickup repaired product with 95% confidance? | The repair time can be represented by an exponential distribution with λ=1/3, the number of repairs per day. . np.random.seed(8) manf_time = np.random.exponential(3, 10000) . manf_time . array([ 6.20086514, 10.37717835, 6.1021323 , ..., 5.30842985, 1.94993868, 3.36773582]) . n5p_value = np.percentile(manf_time, 95) n5p_value . 8.912912006371394 . The customer should wait atleast 9 days to be 95% sure that the repair has done. . Log Normal . it describes a random variable whose logarithm is normally distributed. .",
            "url": "https://udibhaskar.github.io/practical-ml/probability/distribution/bernoulli/binomial/normal/poission/geometric/lognormal/2020/06/05/Distributions.html",
            "relUrl": "/probability/distribution/bernoulli/binomial/normal/poission/geometric/lognormal/2020/06/05/Distributions.html",
            "date": " • Jun 5, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://udibhaskar.github.io/practical-ml/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I am a Machine Learning Engineer with four years of industry experience. Currently working on Query resolution systems and semantic similarity search with NLP. Involve in research and designing an approach, followed by code development. You can check my Linkedin and GitHub .",
          "url": "https://udibhaskar.github.io/practical-ml/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://udibhaskar.github.io/practical-ml/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}